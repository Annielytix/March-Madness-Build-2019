{"cells":[{"cell_type":"markdown","source":["Start off with a bunch of different imports. A lot of these come from Scikit Learn."],"metadata":{}},{"cell_type":"code","source":["import sklearn\nimport pandas as pd\nimport numpy as np\nimport tensorflow\nfrom __future__ import division\nimport collections\n#from sklearn.cross_validation import train_test_split\nfrom sklearn import svm\nfrom sklearn.svm import SVC\nfrom sklearn import linear_model\nfrom sklearn import tree\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D, MaxPooling2D, Convolution1D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom keras.optimizers import SGD\n#from sklearn.cross_validation import cross_val_score\nfrom keras.utils import np_utils\nfrom sklearn.neighbors import KNeighborsClassifier\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nimport sys\nfrom sklearn.ensemble import GradientBoostingRegressor\nimport math\nimport csv\n#%matplotlib inline\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.metrics import classification_report\nimport urllib\nfrom sklearn.svm import LinearSVC\n#from utils import *"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"markdown","source":["# Visualizing All the Historical Data"],"metadata":{"deletable":true,"editable":true}},{"cell_type":"markdown","source":["Let's first take a look at all the historical data we have. These are stats from the 1985 - 2016 NCAA basketball seasons."],"metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":["# This one contains stats for every single regular season game played between 1985 and 2015. It mainly\n# contains info on the score of the game, the IDs for each team, and where the game was played.\nreg_season_compact_pd = pd.read_csv('https://blackrock0204344326.blob.core.windows.net/azureml/LocalUpload/RegularSeasonCompactResults.csv')\nreg_season_compact_pd.head()"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">4</span><span class=\"ansired\">]: </span>\n   Season  Daynum  Wteam  Wscore  Lteam  Lscore Wloc  Numot\n0    1985      20   1228      81   1328      64    N      0\n1    1985      25   1106      77   1354      70    H      0\n2    1985      25   1112      63   1223      56    H      0\n3    1985      25   1165      70   1432      54    H      0\n4    1985      25   1192      86   1447      74    H      0\n</div>"]}}],"execution_count":5},{"cell_type":"code","source":["# This one expands on the previous data frame by going into more in depth stats like 3 point field goals,\n# free throws, steals, blocks, etc. \nreg_season_detailed_pd = pd.read_csv('https://blackrock0204344326.blob.core.windows.net/azureml/LocalUpload/RegularSeasonDetailedResults.csv')\nreg_season_detailed_pd.columns"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">5</span><span class=\"ansired\">]: </span>\nIndex([&apos;Season&apos;, &apos;Daynum&apos;, &apos;Wteam&apos;, &apos;Wscore&apos;, &apos;Lteam&apos;, &apos;Lscore&apos;, &apos;Wloc&apos;,\n       &apos;Numot&apos;, &apos;Wfgm&apos;, &apos;Wfga&apos;, &apos;Wfgm3&apos;, &apos;Wfga3&apos;, &apos;Wftm&apos;, &apos;Wfta&apos;, &apos;Wor&apos;, &apos;Wdr&apos;,\n       &apos;Wast&apos;, &apos;Wto&apos;, &apos;Wstl&apos;, &apos;Wblk&apos;, &apos;Wpf&apos;, &apos;Lfgm&apos;, &apos;Lfga&apos;, &apos;Lfgm3&apos;, &apos;Lfga3&apos;,\n       &apos;Lftm&apos;, &apos;Lfta&apos;, &apos;Lor&apos;, &apos;Ldr&apos;, &apos;Last&apos;, &apos;Lto&apos;, &apos;Lstl&apos;, &apos;Lblk&apos;, &apos;Lpf&apos;],\n      dtype=&apos;object&apos;)\n</div>"]}}],"execution_count":6},{"cell_type":"code","source":["# Don't think this data is honestly that important. Just contains the region areas for the tournament each \n# year. There isn't really a distinct \"home field\" advantage in the tourney because the games are supposed\n# to be on neutral sites. \nseasons_pd = pd.read_csv('https://blackrock0204344326.blob.core.windows.net/azureml/LocalUpload/Seasons.csv')\nseasons_pd.head()"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">6</span><span class=\"ansired\">]: </span>\n   Season     Dayzero Regionw    Regionx    Regiony    Regionz\n0    1985  10/29/1984    East       West    Midwest  Southeast\n1    1986  10/28/1985    East    Midwest  Southeast       West\n2    1987  10/27/1986    East  Southeast    Midwest       West\n3    1988   11/2/1987    East    Midwest  Southeast       West\n4    1989  10/31/1988    East       West    Midwest  Southeast\n</div>"]}}],"execution_count":7},{"cell_type":"code","source":["teams_pd = pd.read_csv('https://blackrock0204344326.blob.core.windows.net/azureml/LocalUpload/Teams.csv')\nteamList = teams_pd['Team_Name'].tolist()\nteams_pd.tail()"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">7</span><span class=\"ansired\">]: </span>\n     Team_Id      Team_Name\n359     1460      Wright St\n360     1461        Wyoming\n361     1462         Xavier\n362     1463           Yale\n363     1464  Youngstown St\n</div>"]}}],"execution_count":8},{"cell_type":"code","source":["# Print Kansas because Frank Mason is hella good\nprint (teams_pd[teams_pd['Team_Name'] == 'Kansas'])"],"metadata":{"collapsed":false},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">     Team_Id Team_Name\n141     1242    Kansas\n</div>"]}}],"execution_count":9},{"cell_type":"code","source":["# Jk, Lonzo > Mason\nprint (teams_pd[teams_pd['Team_Name'] == 'UCLA'])"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">     Team_Id Team_Name\n316     1417      UCLA\n</div>"]}}],"execution_count":10},{"cell_type":"code","source":["# This one contains the stats for every single NCAA tournament game from 1985 to 2015\ntourney_compact_pd = pd.read_csv('https://blackrock0204344326.blob.core.windows.net/azureml/LocalUpload/TourneyCompactResults.csv')\ntourney_compact_pd.head()"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">11</span><span class=\"ansired\">]: </span>\n   Season  Daynum  Wteam  Wscore  Lteam  Lscore Wloc  Numot\n0    1985     136   1116      63   1234      54    N      0\n1    1985     136   1120      59   1345      58    N      0\n2    1985     136   1207      68   1250      43    N      0\n3    1985     136   1229      58   1425      55    N      0\n4    1985     136   1242      49   1325      38    N      0\n</div>"]}}],"execution_count":11},{"cell_type":"code","source":["# More deatiled tourney stats (except only stats from 2003 :( )\ntourney_detailed_pd = pd.read_csv('https://blackrock0204344326.blob.core.windows.net/azureml/LocalUpload/TourneyDetailedResults.csv')\ntourney_detailed_pd.head()"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">12</span><span class=\"ansired\">]: </span>\n   Season  Daynum  Wteam  Wscore  Lteam ...   Last Lto  Lstl  Lblk  Lpf\n0    2003     134   1421      92   1411 ...     16  15     5     0   22\n1    2003     136   1112      80   1436 ...     12  17    10     3   15\n2    2003     136   1113      84   1272 ...     11  12     2     5   18\n3    2003     136   1141      79   1166 ...     20  21     6     6   21\n4    2003     136   1143      76   1301 ...     16  14     5     8   19\n\n[5 rows x 34 columns]\n</div>"]}}],"execution_count":12},{"cell_type":"code","source":["# This one tells you what seed each team was for a given tournament year\ntourney_seeds_pd = pd.read_csv('https://blackrock0204344326.blob.core.windows.net/azureml/LocalUpload/TourneySeeds.csv')\ntourney_seeds_pd.head()"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">13</span><span class=\"ansired\">]: </span>\n   Season Seed  Team\n0    1985  W01  1207\n1    1985  W02  1210\n2    1985  W03  1228\n3    1985  W04  1260\n4    1985  W05  1374\n</div>"]}}],"execution_count":13},{"cell_type":"code","source":["# Seeing what seed Duke was in every tourney\nduke_id = teams_pd[teams_pd['Team_Name'] == 'Duke'].values[0][0]\ntourney_seeds_pd[tourney_seeds_pd['Team'] == duke_id]"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">14</span><span class=\"ansired\">]: </span>\n      Season Seed  Team\n34      1985  Y03  1181\n64      1986  W01  1181\n164     1987  Y05  1181\n193     1988  W02  1181\n257     1989  W02  1181\n322     1990  W03  1181\n417     1991  Y02  1181\n448     1992  W01  1181\n530     1993  X03  1181\n593     1994  X02  1181\n743     1996  Y08  1181\n785     1997  X02  1181\n880     1998  Z01  1181\n896     1999  W01  1181\n960     2000  W01  1181\n1024    2001  W01  1181\n1122    2002  Y01  1181\n1205    2003  Z03  1181\n1219    2004  W01  1181\n1316    2005  Y01  1181\n1349    2006  W01  1181\n1467    2007  Z06  1181\n1529    2008  Z02  1181\n1545    2009  W02  1181\n1625    2010  X01  1181\n1692    2011  X01  1181\n1777    2012  Y02  1181\n1844    2013  Y02  1181\n1913    2014  Y03  1181\n1963    2015  X01  1181\n2068    2016  Z04  1181\n</div>"]}}],"execution_count":14},{"cell_type":"code","source":["# Don't know how helpful this is tbh, because it just tells you what the seeds of the stronger\n# and weaker seeds are (assuming that the favored team wins??), so its always 1 vs 16 and then \n# 1 vs 8 and 1 vs 4..\ntourney_slots_pd = pd.read_csv('https://blackrock0204344326.blob.core.windows.net/azureml/LocalUpload/TourneySlots.csv')\ntourney_slots_pd.head()"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">15</span><span class=\"ansired\">]: </span>\n   Season  Slot Strongseed Weakseed\n0    1985  R1W1        W01      W16\n1    1985  R1W2        W02      W15\n2    1985  R1W3        W03      W14\n3    1985  R1W4        W04      W13\n4    1985  R1W5        W05      W12\n</div>"]}}],"execution_count":15},{"cell_type":"code","source":["conference_pd = pd.read_csv('https://blackrock0204344326.blob.core.windows.net/azureml/LocalUpload/Conference.csv')\nconference_pd.head()"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">16</span><span class=\"ansired\">]: </span>\n   Year       ...        Tournament Champ\n0  2003       ...                Kentucky\n1  2003       ...                Oklahoma\n2  2003       ...                    Duke\n3  2003       ...              Pittsburgh\n4  2003       ...                Illinois\n\n[5 rows x 13 columns]\n</div>"]}}],"execution_count":16},{"cell_type":"code","source":["tourney_results_pd = pd.read_csv('https://blackrock0204344326.blob.core.windows.net/azureml/LocalUpload/TourneyResults.csv')\ntourney_results_pd.head()"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">18</span><span class=\"ansired\">]: </span>\n   Rk           Season       ...        Naismith Award    Wooden Award\n0   1  2016-17 Summary       ...                   NaN             NaN\n1   2  2015-16 Summary       ...           Buddy Hield     Buddy Hield\n2   3  2014-15 Summary       ...        Frank Kaminsky  Frank Kaminsky\n3   4  2013-14 Summary       ...        Doug McDermott  Doug McDermott\n4   5  2012-13 Summary       ...            Trey Burke      Trey Burke\n\n[5 rows x 7 columns]\n</div>"]}}],"execution_count":17},{"cell_type":"code","source":["\nNCAAChampionsList = tourney_results_pd['NCAA Champion'].tolist()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":18},{"cell_type":"markdown","source":["# Feature Selection"],"metadata":{"deletable":true,"editable":true}},{"cell_type":"markdown","source":["Let's make this supervised trianing problem where our model with take in 2 d dimensional vectors, representing the two teams playing in the tournament. Each d dimensional vector will contain information about the team for that year. Below are the features we end up using. \n\n* Regular Season Wins \n* Points per game season average \n* Points per game allowed season average\n* Whether or not in Power 6 conference (ACC, Big Ten, Big 12, SEC, Pac 12, Big East) - Binary label\n* Number of 3's per game\n* Turnovers per game average\n* Assists per game average\n* Conference Championship - binary label\n* Conference Tournament Championship - binary label\n* Tournament Seed\n* Strength of Schedule\n* Simple Rating System\n* Rebounds per game average\n* Steals per game average\n* Number of NCAA appearances since 1985\n* Whether the team is home or away or neutral (labels -1, 0, and 1)"],"metadata":{"deletable":true,"editable":true}},{"cell_type":"markdown","source":["# Functions To Help Feature Selection"],"metadata":{"deletable":true,"editable":true}},{"cell_type":"markdown","source":["These functions help us obtain all the information that will eventually go in our team vectors."],"metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":["listACCteams = ['North Carolina','Virginia','Florida St','Louisville','Notre Dame','Syracuse','Duke','Virginia Tech','Georgia Tech','Miami','Wake Forest','Clemson','NC State','Boston College','Pittsburgh']\nlistPac12teams = ['Arizona','Oregon','UCLA','California','USC','Utah','Washington St','Stanford','Arizona St','Colorado','Washington','Oregon St']\nlistSECteams = ['Kentucky','South Carolina','Florida','Arkansas','Alabama','Tennessee','Mississippi St','Georgia','Ole Miss','Vanderbilt','Auburn','Texas A&M','LSU','Missouri']\nlistBig10teams = ['Maryland','Wisconsin','Purdue','Northwestern','Michigan St','Indiana','Iowa','Michigan','Penn St','Nebraska','Minnesota','Illinois','Ohio St','Rutgers']\nlistBig12teams = ['Kansas','Baylor','West Virginia','Iowa St','TCU','Kansas St','Texas Tech','Oklahoma St','Texas','Oklahoma']\nlistBigEastteams = ['Butler','Creighton','DePaul','Georgetown','Marquette','Providence','Seton Hall','St John\\'s','Villanova','Xavier']"],"metadata":{"collapsed":true,"deletable":true,"editable":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":23},{"cell_type":"code","source":["def checkPower6Conference(team_id):\n    teamName = teams_pd.values[team_id-1101][1]\n    if (teamName in listACCteams or teamName in listBig10teams or teamName in listBig12teams\n       or teamName in listSECteams or teamName in listPac12teams or teamName in listBigEastteams):\n        return 1\n    else:\n        return 0"],"metadata":{"collapsed":true,"deletable":true,"editable":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":24},{"cell_type":"code","source":["def getTeamID(name):\n    return teams_pd[teams_pd['Team_Name'] == name].values[0][0]"],"metadata":{"collapsed":true,"deletable":true,"editable":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":25},{"cell_type":"code","source":["def getTeamName(team_id):\n    return teams_pd[teams_pd['Team_Id'] == team_id].values[0][1]"],"metadata":{"collapsed":true,"deletable":true,"editable":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":26},{"cell_type":"code","source":["def getNumChampionships(team_id):\n    name = getTeamName(team_id)\n    return NCAAChampionsList.count(name)"],"metadata":{"collapsed":true,"deletable":true,"editable":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":27},{"cell_type":"code","source":["def getListForURL(team_list):\n    team_list = [x.lower() for x in team_list]\n    team_list = [t.replace(' ', '-') for t in team_list]\n    team_list = [t.replace('st', 'state') for t in team_list]\n    team_list = [t.replace('northern-dakota', 'north-dakota') for t in team_list]\n    team_list = [t.replace('nc-', 'north-carolina-') for t in team_list]\n    team_list = [t.replace('fl-', 'florida-') for t in team_list]\n    team_list = [t.replace('ga-', 'georgia-') for t in team_list]\n    team_list = [t.replace('lsu', 'louisiana-state') for t in team_list]\n    team_list = [t.replace('maristate', 'marist') for t in team_list]\n    team_list = [t.replace('stateate', 'state') for t in team_list]\n    team_list = [t.replace('northernorthern', 'northern') for t in team_list]\n    team_list = [t.replace('usc', 'southern-california') for t in team_list]\n    base = 'http://www.sports-reference.com/cbb/schools/'\n    for team in team_list:\n        url = base + team + '/'\ngetListForURL(teamList);"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":28},{"cell_type":"code","source":["# Function for handling the annoying cases of Florida and FL, as well as State and St\ndef handleCases(arr):\n    indices = []\n    listLen = len(arr)\n    for i in range(listLen):\n        if (arr[i] == 'St' or arr[i] == 'FL'):\n            indices.append(i)\n    for p in indices:\n        arr[p-1] = arr[p-1] + ' ' + arr[p]\n    for i in range(len(indices)): \n        arr.remove(arr[indices[i] - i])\n    return arr"],"metadata":{"collapsed":true,"deletable":true,"editable":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":29},{"cell_type":"code","source":["def checkConferenceChamp(team_id, year):\n    year_conf_pd = conference_pd[conference_pd['Year'] == year]\n    champs = year_conf_pd['Regular Season Champ'].tolist()\n    # For handling cases where there is more than one champion\n    champs_separated = [words for segments in champs for words in segments.split()]\n    name = getTeamName(team_id)\n    champs_separated = handleCases(champs_separated)\n    if (name in champs_separated):\n        return 1\n    else:\n        return 0"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":30},{"cell_type":"code","source":["def checkConferenceTourneyChamp(team_id, year):\n    year_conf_pd = conference_pd[conference_pd['Year'] == year]\n    champs = year_conf_pd['Tournament Champ'].tolist()\n    name = getTeamName(team_id)\n    if (name in champs):\n        return 1\n    else:\n        return 0"],"metadata":{"collapsed":true,"deletable":true,"editable":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":31},{"cell_type":"code","source":["def getTourneyAppearances(team_id):\n    return len(tourney_seeds_pd[tourney_seeds_pd['Team'] == team_id].index)"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":32},{"cell_type":"code","source":["def handleDifferentCSV(df):\n    # The stats CSV is a lit different in terms of naming so below is just some data cleaning\n    df['School'] = df['School'].replace('(State)', 'St', regex=True) \n    df['School'] = df['School'].replace('Albany (NY)', 'Albany NY') \n    df['School'] = df['School'].replace('Boston University', 'Boston Univ')\n    df['School'] = df['School'].replace('Central Michigan', 'C Michigan')\n    df['School'] = df['School'].replace('(Eastern)', 'E', regex=True)\n    df['School'] = df['School'].replace('Louisiana St', 'LSU')\n    df['School'] = df['School'].replace('North Carolina St', 'NC State')\n    df['School'] = df['School'].replace('Southern California', 'USC')\n    df['School'] = df['School'].replace('University of California', 'California', regex=True) \n    df['School'] = df['School'].replace('American', 'American Univ')\n    df['School'] = df['School'].replace('Arkansas-Little Rock', 'Ark Little Rock')\n    df['School'] = df['School'].replace('Arkansas-Pine Bluff', 'Ark Pine Bluff')\n    df['School'] = df['School'].replace('Bowling Green St', 'Bowling Green')\n    df['School'] = df['School'].replace('Brigham Young', 'BYU')\n    df['School'] = df['School'].replace('Cal Poly', 'Cal Poly SLO')\n    df['School'] = df['School'].replace('Centenary (LA)', 'Centenary')\n    df['School'] = df['School'].replace('Central Connecticut St', 'Central Conn')\n    df['School'] = df['School'].replace('Charleston Southern', 'Charleston So')\n    df['School'] = df['School'].replace('Coastal Carolina', 'Coastal Car')\n    df['School'] = df['School'].replace('College of Charleston', 'Col Charleston')\n    df['School'] = df['School'].replace('Cal St Fullerton', 'CS Fullerton')\n    df['School'] = df['School'].replace('Cal St Sacramento', 'CS Sacramento')\n    df['School'] = df['School'].replace('Cal St Bakersfield', 'CS Bakersfield')\n    df['School'] = df['School'].replace('Cal St Northridge', 'CS Northridge')\n    df['School'] = df['School'].replace('East Tennessee St', 'ETSU')\n    df['School'] = df['School'].replace('Detroit Mercy', 'Detroit')\n    df['School'] = df['School'].replace('Fairleigh Dickinson', 'F Dickinson')\n    df['School'] = df['School'].replace('Florida Atlantic', 'FL Atlantic')\n    df['School'] = df['School'].replace('Florida Gulf Coast', 'FL Gulf Coast')\n    df['School'] = df['School'].replace('Florida International', 'Florida Intl')\n    df['School'] = df['School'].replace('George Washington', 'G Washington')\n    df['School'] = df['School'].replace('Georgia Southern', 'Ga Southern')\n    df['School'] = df['School'].replace('Gardner-Webb', 'Gardner Webb')\n    df['School'] = df['School'].replace('Illinois-Chicago', 'IL Chicago')\n    df['School'] = df['School'].replace('Kent St', 'Kent')\n    df['School'] = df['School'].replace('Long Island University', 'Long Island')\n    df['School'] = df['School'].replace('Loyola Marymount', 'Loy Marymount')\n    df['School'] = df['School'].replace('Loyola (MD)', 'Loyola MD')\n    df['School'] = df['School'].replace('Loyola (IL)', 'Loyola-Chicago')\n    df['School'] = df['School'].replace('Massachusetts', 'MA Lowell')\n    df['School'] = df['School'].replace('Maryland-Eastern Shore', 'MD E Shore')\n    df['School'] = df['School'].replace('Miami (FL)', 'Miami FL')\n    df['School'] = df['School'].replace('Miami (OH)', 'Miami OH')\n    df['School'] = df['School'].replace('Missouri-Kansas City', 'Missouri KC')\n    df['School'] = df['School'].replace('Monmouth', 'Monmouth NJ')\n    df['School'] = df['School'].replace('Mississippi Valley St', 'MS Valley St')\n    df['School'] = df['School'].replace('Montana St', 'MTSU')\n    df['School'] = df['School'].replace('Northern Colorado', 'N Colorado')\n    df['School'] = df['School'].replace('North Dakota St', 'N Dakota St')\n    df['School'] = df['School'].replace('Northern Illinois', 'N Illinois')\n    df['School'] = df['School'].replace('Northern Kentucky', 'N Kentucky')\n    df['School'] = df['School'].replace('North Carolina A&T', 'NC A&T')\n    df['School'] = df['School'].replace('North Carolina Central', 'NC Central')\n    df['School'] = df['School'].replace('Pennsylvania', 'Penn')\n    df['School'] = df['School'].replace('South Carolina St', 'S Carolina St')\n    df['School'] = df['School'].replace('Southern Illinois', 'S Illinois')\n    df['School'] = df['School'].replace('UC-Santa Barbara', 'Santa Barbara')\n    df['School'] = df['School'].replace('Southeastern Louisiana', 'SE Louisiana')\n    df['School'] = df['School'].replace('Southeast Missouri St', 'SE Missouri St')\n    df['School'] = df['School'].replace('Stephen F. Austin', 'SF Austin')\n    df['School'] = df['School'].replace('Southern Methodist', 'SMU')\n    df['School'] = df['School'].replace('Southern Mississippi', 'Southern Miss')\n    df['School'] = df['School'].replace('Southern', 'Southern Univ')\n    df['School'] = df['School'].replace('St. Bonaventure', 'St Bonaventure')\n    df['School'] = df['School'].replace('St. Francis (NY)', 'St Francis NY')\n    df['School'] = df['School'].replace('Saint Francis (PA)', 'St Francis PA')\n    df['School'] = df['School'].replace('St. John\\'s (NY)', 'St John\\'s')\n    df['School'] = df['School'].replace('Saint Joseph\\'s', 'St Joseph\\'s PA')\n    df['School'] = df['School'].replace('Saint Louis', 'St Louis')\n    df['School'] = df['School'].replace('Saint Mary\\'s (CA)', 'St Mary\\'s CA')\n    df['School'] = df['School'].replace('Mount Saint Mary\\'s', 'Mt St Mary\\'s')\n    df['School'] = df['School'].replace('Saint Peter\\'s', 'St Peter\\'s')\n    df['School'] = df['School'].replace('Texas A&M-Corpus Christian', 'TAM C. Christian')\n    df['School'] = df['School'].replace('Texas Christian', 'TCU')\n    df['School'] = df['School'].replace('Tennessee-Martin', 'TN Martin')\n    df['School'] = df['School'].replace('Texas-Rio Grande Valley', 'UTRGV')\n    df['School'] = df['School'].replace('Texas Southern', 'TX Southern')\n    df['School'] = df['School'].replace('Alabama-Birmingham', 'UAB')\n    df['School'] = df['School'].replace('UC-Davis', 'UC Davis')\n    df['School'] = df['School'].replace('UC-Irvine', 'UC Irvine')\n    df['School'] = df['School'].replace('UC-Riverside', 'UC Riverside')\n    df['School'] = df['School'].replace('Central Florida', 'UCF')\n    df['School'] = df['School'].replace('Louisiana-Lafayette', 'ULL')\n    df['School'] = df['School'].replace('Louisiana-Monroe', 'ULM')\n    df['School'] = df['School'].replace('Maryland-Baltimore County', 'UMBC')\n    df['School'] = df['School'].replace('North Carolina-Asheville', 'UNC Asheville')\n    df['School'] = df['School'].replace('North Carolina-Greensboro', 'UNC Greensboro')\n    df['School'] = df['School'].replace('North Carolina-Wilmington', 'UNC Wilmington')\n    df['School'] = df['School'].replace('Nevada-Las Vegas', 'UNLV')\n    df['School'] = df['School'].replace('Texas-Arlington', 'UT Arlington')\n    df['School'] = df['School'].replace('Texas-San Antonio', 'UT San Antonio')\n    df['School'] = df['School'].replace('Texas-El Paso', 'UTEP')\n    df['School'] = df['School'].replace('Virginia Commonwealth', 'VA Commonwealth')\n    df['School'] = df['School'].replace('Western Carolina', 'W Carolina')\n    df['School'] = df['School'].replace('Western Illinois', 'W Illinois')\n    df['School'] = df['School'].replace('Western Kentucky', 'WKU')\n    df['School'] = df['School'].replace('Western Michigan', 'W Michigan')\n    df['School'] = df['School'].replace('Abilene Christian', 'Abilene Chr')\n    df['School'] = df['School'].replace('Montana State', 'Montana St')\n    df['School'] = df['School'].replace('Central Arkansas', 'Cent Arkansas')\n    df['School'] = df['School'].replace('Houston Baptist', 'Houston Bap')\n    df['School'] = df['School'].replace('South Dakota St', 'S Dakota St')\n    df['School'] = df['School'].replace('Maryland-Eastern Shore', 'MD E Shore')\n    return df"],"metadata":{"collapsed":true,"deletable":true,"editable":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":33},{"cell_type":"markdown","source":["# Obtaining Season Vectors"],"metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":["def getSeasonData(team_id, year):\n    # The data frame below holds stats for every single game in the given year\n    year_data_pd = reg_season_compact_pd[reg_season_compact_pd['Season'] == year]\n    # Finding number of points per game\n    gamesWon = year_data_pd[year_data_pd.Wteam == team_id] \n    totalPointsScored = gamesWon['Wscore'].sum()\n    gamesLost = year_data_pd[year_data_pd.Lteam == team_id] \n    totalGames = gamesWon.append(gamesLost)\n    numGames = len(totalGames.index)\n    totalPointsScored += gamesLost['Lscore'].sum()\n    \n    # Finding number of points per game allowed\n    totalPointsAllowed = gamesWon['Lscore'].sum()\n    totalPointsAllowed += gamesLost['Wscore'].sum()\n    \n    stats_SOS_pd = pd.read_csv('https://blackrock0204344326.blob.core.windows.net/azureml/LocalUpload/MMStats_'+str(year)+'.csv')\n    stats_SOS_pd = handleDifferentCSV(stats_SOS_pd)\n    ratings_pd = pd.read_csv('https://blackrock0204344326.blob.core.windows.net/azureml/LocalUpload/RatingStats_'+str(year)+'.csv')\n    ratings_pd = handleDifferentCSV(ratings_pd)\n    \n    name = getTeamName(team_id)\n    team = stats_SOS_pd[stats_SOS_pd['School'] == name]\n    team_rating = ratings_pd[ratings_pd['School'] == name]\n    if (len(team.index) == 0 or len(team_rating.index) == 0): #Can't find the team\n        total3sMade = 0\n        totalTurnovers = 0\n        totalAssists = 0\n        sos = 0\n        totalRebounds = 0\n        srs = 0\n        totalSteals = 0\n    else:\n        total3sMade = team['X3P'].values[0]\n        totalTurnovers = team['TOV'].values[0]\n        if (math.isnan(totalTurnovers)):\n            totalTurnovers = 0\n        totalAssists = team['AST'].values[0]\n        if (math.isnan(totalAssists)):\n            totalAssists = 0\n        sos = team['SOS'].values[0]\n        srs = team['SRS'].values[0]\n        totalRebounds = team['TRB'].values[0]\n        if (math.isnan(totalRebounds)):\n            totalRebounds = 0\n        totalSteals = team['STL'].values[0]\n        if (math.isnan(totalSteals)):\n            totalSteals = 0\n    \n    #Finding tournament seed for that year\n    tourneyYear = tourney_seeds_pd[tourney_seeds_pd['Season'] == year]\n    seed = tourneyYear[tourneyYear['Team'] == team_id]\n    if (len(seed.index) != 0):\n        seed = seed.values[0][1]\n        tournamentSeed = int(seed[1:3])\n    else:\n        tournamentSeed = 25 #Not sure how to represent if a team didn't make the tourney\n    \n    # Finding number of wins and losses\n    numWins = len(gamesWon.index)\n    # There are some teams who may have dropped to Division 2, so they won't have games \n    # a certain year. In this case, we don't want to divide by 0, so we'll just set the\n    # averages to 0 instead\n    if numGames == 0:\n        avgPointsScored = 0\n        avgPointsAllowed = 0\n        avg3sMade = 0\n        avgTurnovers = 0\n        avgAssists = 0\n        avgRebounds = 0\n        avgSteals = 0\n    else:\n        avgPointsScored = totalPointsScored/numGames\n        avgPointsAllowed = totalPointsAllowed/numGames\n        avg3sMade = total3sMade/numGames\n        avgTurnovers = totalTurnovers/numGames\n        avgAssists = totalAssists/numGames\n        avgRebounds = totalRebounds/numGames\n        avgSteals = totalSteals/numGames\n    #return [numWins, sos, srs]\n    #return [numWins, avgPointsScored, avgPointsAllowed, checkPower6Conference(team_id), avg3sMade, avg3sAllowed, avgTurnovers,\n    #        tournamentSeed, getStrengthOfSchedule(team_id, year), getTourneyAppearances(team_id)]\n    return [numWins, avgPointsScored, avgPointsAllowed, checkPower6Conference(team_id), avg3sMade, avgAssists, avgTurnovers,\n           checkConferenceChamp(team_id, year), checkConferenceTourneyChamp(team_id, year), tournamentSeed,\n            sos, srs, avgRebounds, avgSteals, getTourneyAppearances(team_id), getNumChampionships(team_id)]"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":35},{"cell_type":"markdown","source":["The following code tests out whether we can get Kentucky's season vector for 2016"],"metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":["kentucky_id = teams_pd[teams_pd['Team_Name'] == 'Kentucky'].values[0][0]\ngetSeasonData(kentucky_id, 2016)"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">32</span><span class=\"ansired\">]: </span>\n[26,\n 79.67647058823529,\n 68.26470588235294,\n 1,\n 7.176470588235294,\n 15.058823529411764,\n 11.823529411764707,\n 1,\n 1,\n 4,\n 8.84,\n 20.23,\n 41.029411764705884,\n 6.0588235294117645,\n 27,\n 3]\n</div>"]}}],"execution_count":37},{"cell_type":"code","source":["def compareTwoTeams(id_1, id_2, year):\n    team_1 = getSeasonData(id_1, year)\n    team_2 = getSeasonData(id_2, year)\n    diff = [a - b for a, b in zip(team_1, team_2)]\n    return diff"],"metadata":{"collapsed":true,"deletable":true,"editable":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":38},{"cell_type":"markdown","source":["Here, we look at the difference vector between Kansas and Kentucky in 2016"],"metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":["kansas_id = teams_pd[teams_pd['Team_Name'] == 'Kansas'].values[0][0]\ncompareTwoTeams(kansas_id, kentucky_id, 2016)"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">34</span><span class=\"ansired\">]: </span>\n[3,\n 0.6265597147950075,\n -0.6586452762923329,\n 0,\n 2.0356506238859184,\n 3.24420677361854,\n 2.570409982174688,\n 0,\n 0,\n -3,\n 2.380000000000001,\n 3.6400000000000006,\n 2.6978609625668426,\n 1.6078431372549025,\n 4,\n -1]\n</div>"]}}],"execution_count":40},{"cell_type":"markdown","source":["This method returns the team vectors for each NCAA team for the given season. This information is held in a Python dictionary."],"metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":["def createSeasonDict(year):\n    seasonDictionary = collections.defaultdict(list)\n    for team in teamList:\n        team_id = teams_pd[teams_pd['Team_Name'] == team].values[0][0]\n        team_vector = getSeasonData(team_id, year)\n        seasonDictionary[team_id] = team_vector\n    return seasonDictionary"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":42},{"cell_type":"code","source":["def getHomeStat(row):\n    if (row == 'H'):\n        home = 1\n    if (row == 'A'):\n        home = -1\n    if (row == 'N'):\n        home = 0\n    return home"],"metadata":{"collapsed":true,"deletable":true,"editable":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":43},{"cell_type":"markdown","source":["This is the most important method, where we create our training set. The idea is that we go through each of the years that are passed in, and we obtain a season dictionary for each year (by calling the previous method). Then, we look at each game that took place over the course of the season. This data is held in the reg_season_compact_pd dataframe. This dataframe contains information about the 5,200 games that occurred. For each of these games, we take a look at the two teams playing, obtain their team vectors, and then take the difference between the two. This new resultant vector is used as a sort of \"representation\" of the differences between the 2 teams playing. This vector will be our the X (or the input) for our supervised learning problem. The Y (or the label) will be a 1 if Team 1 wins. The way we introduce negative sampling is by associating the negative of the X vector with the label of 0."],"metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":["def createTrainingSet(years):\n    totalNumGames = 0\n    for year in years:\n        season = reg_season_compact_pd[reg_season_compact_pd['Season'] == year]\n        totalNumGames += len(season.index)\n        tourney = tourney_compact_pd[tourney_compact_pd['Season'] == year]\n        totalNumGames += len(tourney.index)\n    numFeatures = len(getSeasonData(1181,2012)) #Just choosing a random team and seeing the dimensionality of the vector\n    xTrain = np.zeros(( totalNumGames, numFeatures + 1))\n    yTrain = np.zeros(( totalNumGames ))\n    indexCounter = 0\n    for year in years:\n        team_vectors = createSeasonDict(year)\n        season = reg_season_compact_pd[reg_season_compact_pd['Season'] == year]\n        numGamesInSeason = len(season.index)\n        tourney = tourney_compact_pd[tourney_compact_pd['Season'] == year]\n        numGamesInSeason += len(tourney.index)\n        xTrainSeason = np.zeros(( numGamesInSeason, numFeatures + 1))\n        yTrainSeason = np.zeros(( numGamesInSeason ))\n        counter = 0\n        for index, row in season.iterrows():\n            w_team = row['Wteam']\n            w_vector = team_vectors[w_team]\n            l_team = row['Lteam']\n            l_vector = team_vectors[l_team]\n            diff = [a - b for a, b in zip(w_vector, l_vector)]\n            home = getHomeStat(row['Wloc'])\n            if (counter % 2 == 0):\n                diff.append(home) \n                xTrainSeason[counter] = diff\n                yTrainSeason[counter] = 1\n            else:\n                diff.append(-home)\n                xTrainSeason[counter] = [ -p for p in diff]\n                yTrainSeason[counter] = 0\n            counter += 1\n        for index, row in tourney.iterrows():\n            w_team = row['Wteam']\n            w_vector = team_vectors[w_team]\n            l_team = row['Lteam']\n            l_vector = team_vectors[l_team]\n            diff = [a - b for a, b in zip(w_vector, l_vector)]\n            home = 0 #All tournament games are neutral\n            if (counter % 2 == 0):\n                diff.append(home) \n                xTrainSeason[counter] = diff\n                yTrainSeason[counter] = 1\n            else:\n                diff.append(-home)\n                xTrainSeason[counter] = [ -p for p in diff]\n                yTrainSeason[counter] = 0\n            counter += 1\n        xTrain[indexCounter:numGamesInSeason+indexCounter] = xTrainSeason\n        yTrain[indexCounter:numGamesInSeason+indexCounter] = yTrainSeason\n        indexCounter += numGamesInSeason\n    return xTrain, yTrain"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":45},{"cell_type":"code","source":["def normalizeInput(arr):\n    for i in range(arr.shape[1]):\n        minVal = min(arr[:,i])\n        maxVal = max(arr[:,i])\n        arr[:,i] =  (arr[:,i] - minVal) / (maxVal - minVal)\n    return arr\n# alternative:\ndef normalize(X):\n    return (X - np.mean(X, axis = 0)) / np.std(X, axis = 0)"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":46},{"cell_type":"markdown","source":["The code below takes a while to run, so I've commented it out right now, and you can just load in the precomputed matrices in the code block after that."],"metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":["years = range(1993,2017)\nxTrain2, yTrain2 = createTrainingSet(years)\n#np.save('xTrain', xTrain)\nnp.save('https://blackrock0204344326.blob.core.windows.net/azureml/LocalUpload/xTrain2.npy',xTrain2)\nnp.save('https://blackrock0204344326.blob.core.windows.net/azureml/LocalUpload/yTrain2.npy',yTrain2)\n#np.save('yTrain', yTrain)"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":48},{"cell_type":"code","source":["import numpy as np\nxTrain2 = np.load('https://blackrock0204344326.blob.core.windows.net/azureml/LocalUpload/xTrain2.npy')\nyTrain2 = np.load('https://blackrock0204344326.blob.core.windows.net/azureml/LocalUpload/yTrain2.npy')"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":49},{"cell_type":"code","source":["xTrain.shape"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":50},{"cell_type":"code","source":["yTrain.shape"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":51},{"cell_type":"markdown","source":["# Testing Models"],"metadata":{"deletable":true,"editable":true}},{"cell_type":"markdown","source":["* SVM: **72.24%**\n* Logistic Regression: **76.17%**\n* XGBoost: **76.28%**\n* Multilayered Neural Network: **76.21%**\n* Decision Tree (Classifier and/or Regressor): **65.04%**\n* Gradient Boosted Regressor (n_estimators = 100): **76.30%**\n* Linear SVC: **76.41%**\n* Random Forest Classifier (n = 200): **72.32%**\n* KNN (k = 39): **75.51%**"],"metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":["# These are the different models I tried. Simply uncomment the model that you want to try. \n\n#model = tree.DecisionTreeClassifier()\n#model = tree.DecisionTreeRegressor()\n#model = linear_model.LogisticRegression()\nmodel = linear_model.BayesianRidge()\n#model = linear_model.Lasso()\n#model = svm.SVC()\n#model = svm.SVR()\n#model = linear_model.Ridge(alpha = 0.5)\n#model = AdaBoostClassifier(n_estimators=100)\n#model = GradientBoostingClassifier(n_estimators=100)\n#model = GradientBoostingRegressor(n_estimators=100, max_depth=5)\n#model = RandomForestClassifier(n_estimators=64)\n#model = KNeighborsClassifier(n_neighbors=39)\n#neuralNetwork(10)\n#model = VotingClassifier(estimators=[('GBR', model1), ('BR', model2), ('KNN', model3)], voting='soft')\n#model = LinearSVC(penalty='l2', loss='squared_hinge', dual=True, tol=0.0001, C=0.1)"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":54},{"cell_type":"code","source":["def showDependency(predictions, test, stat, my_categories):\n    difference = test[:,my_categories.index(stat)]\n    plt.scatter(difference, predictions)\n    plt.ylabel('Probability of Team 1 Win')\n    plt.xlabel(stat + ' Difference (Team 1 - Team 2)')\n    plt.show()"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":55},{"cell_type":"code","source":["def showFeatureImportance(my_categories):\n    fx_imp = pd.Series(model.feature_importances_, index=my_categories)\n    fx_imp /= fx_imp.max()\n    fx_imp.sort()\n    fx_imp.plot(kind='barh')"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":56},{"cell_type":"code","source":["categories=['Wins','PPG','PPGA','PowerConf','3PG', 'APG','TOP','Conference Champ','Tourney Conference Champ',\n           'Seed','SOS','SRS', 'RPG', 'SPG', 'Tourney Appearances','National Championships','Location']\naccuracy=[]\n\nfor i in range(1):\n    X_train, X_test, Y_train, Y_test = train_test_split(xTrain, yTrain)\n    results = model.fit(X_train, Y_train)\n    preds = model.predict(X_test)\n\n    preds[preds < .5] = 0\n    preds[preds >= .5] = 1\n    accuracy.append(np.mean(preds == Y_test))\n    #accuracy.append(np.mean(predictions == Y_test))\n    print \"Finished iteration:\", i\nprint \"The accuracy is\", sum(accuracy)/len(accuracy)"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":57},{"cell_type":"markdown","source":["# Testing Ensemble Methods"],"metadata":{"deletable":true,"editable":true}},{"cell_type":"markdown","source":["This section didn't end up working that well, so you can skip over it."],"metadata":{}},{"cell_type":"code","source":["#categories=['Wins','PPG','PPGA','PowerConf','3PG', 'APG','TOP','Conference Champ','Tourney Conference Champ',\n#           'Seed','SOS','SRS', 'RPG', 'SPG', 'Tourney Appearances','National Championships','Location']\n#accuracy=[]\n\n#for i in range(1):\n#    X_train, X_test, Y_train, Y_test = train_test_split(xTrain, yTrain)\n#    results1 = model.fit(X_train, Y_train)\n#    preds1 = model.predict(X_test)\n#    \n#    results2 = model2.fit(X_train, Y_train)\n#    preds2 = model2.predict(X_test)\n    \n#    results3 = model3.fit(X_train, Y_train)\n#    preds3 = model3.predict(X_test)\n\n#    results4 = model4.fit(X_train, Y_train)\n#    preds4 = model4.predict(X_test)\n    \n#    results5 = model5.fit(X_train, Y_train)\n#    preds5 = model5.predict(X_test)\n    \n#    preds = (preds1 + preds2 + preds3 + preds4 + preds5)/5\n\n#    preds[preds < .5] = 0\n#    preds[preds >= .5] = 1\n#    accuracy.append(np.mean(preds == Y_test))\n    #accuracy.append(np.mean(predictions == Y_test))\n#print \"The accuracy is\", sum(accuracy)/len(accuracy)\n#showFeatureImportance(categories)"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":60},{"cell_type":"markdown","source":["# Applying the Model"],"metadata":{"deletable":true,"editable":true}},{"cell_type":"markdown","source":["Depending on the model you use, you will either need to return model.predict_proba or model.predict"],"metadata":{}},{"cell_type":"code","source":["def predictGame(team_1_vector, team_2_vector, home):\n    diff = [a - b for a, b in zip(team_1_vector, team_2_vector)]\n    diff.append(home)\n    return model.predict([diff]) \n    #return model.predict_proba([diff]) "],"metadata":{"collapsed":true,"deletable":true,"editable":true},"outputs":[],"execution_count":63},{"cell_type":"markdown","source":["The output here is"],"metadata":{}},{"cell_type":"code","source":["# This was the national championship matchup last year\nteam1_name = 'North Carolina'\nteam2_name = 'Villanova'\nteam1_vector = getSeasonData(teams_pd[teams_pd['Team_Name'] == team1_name].values[0][0], 2016)\nteam2_vector = getSeasonData(teams_pd[teams_pd['Team_Name'] == team2_name].values[0][0], 2016)\nprint 'Probability that ' + team1_name + ' wins:', predictGame(team1_vector, team2_vector, 0)[0]"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":65},{"cell_type":"markdown","source":["# Predicting NCAA Tourney 2013 - 2016"],"metadata":{"deletable":true,"editable":true}},{"cell_type":"markdown","source":["For the first stage of the Kaggle competition, our job was to submit probabilities for each of the possible scenarios in the 2013, 2014, 2015, and 2016 tournaments."],"metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":["sample_sub_pd = pd.read_csv('Data/sample_submission.csv')\n(sample_sub_pd.head())"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":68},{"cell_type":"code","source":["def createPrediction():\n    results = [[0 for x in range(2)] for x in range(len(sample_sub_pd.index))]\n    for index, row in sample_sub_pd.iterrows():\n        matchup_id = row['id']\n        year = matchup_id[0:4]\n        team1_id = matchup_id[5:9]\n        team2_id = matchup_id[10:14]\n        team1_vector = getSeasonData(int(team1_id), int(year))\n        team2_vector = getSeasonData(int(team2_id), int(year))\n        pred = predictGame(team1_vector, team2_vector, 0)\n        results[index][0] = matchup_id\n        results[index][1] = pred[0]\n        #results[index][1] = pred[0][1]\n    results = pd.np.array(results)\n    firstRow = [[0 for x in range(2)] for x in range(1)]\n    firstRow[0][0] = 'id'\n    firstRow[0][1] = 'pred'\n    with open(\"result.csv\", \"wb\") as f:\n        writer = csv.writer(f)\n        writer.writerows(firstRow)\n        writer.writerows(results)"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":69},{"cell_type":"code","source":["createPrediction()"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":70},{"cell_type":"code","source":["def findBestK():\n    K = (list)(i for i in range(1,200) if i%2!=0)\n    p = []\n    for k in K:\n        kmeans = KNeighborsClassifier(n_neighbors=k)\n        kmeans.fit(X_train, Y_train)\n        results = kmeans.fit(X_train, Y_train)\n        preds = kmeans.predict(X_test)\n        p.append(np.mean(preds == Y_test))\n    plt.plot(K, p)\n    plt.xlabel('k')\n    plt.ylabel('Accuracy')\n    plt.title('Selecting k with the Elbow Method')\n    plt.show()"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":71},{"cell_type":"code","source":["def neuralNetwork(loops):\n    accuracy=[]\n    dim = 17\n    for i in range(loops):\n        X_train, X_test, Y_train, Y_test = train_test_split(xTrain, yTrain)\n\n        model = Sequential()\n        #model.add(Convolution1D(28, 3, border_mode='same', init='normal', input_shape=(dim, 1))) #28 1D filters of length 3\n        model.add(Dense(128, init='normal', input_dim = dim))\n        model.add(Activation('relu'))\n        model.add(Dropout(0.2))\n        model.add(Dense(64, init='normal'))\n        model.add(Activation('relu'))\n        model.add(Dropout(0.1))\n        model.add(Dense(16, init='normal'))\n        model.add(Activation('relu'))\n        model.add(Dense(2, init='normal'))\n        model.add(Activation('softmax'))\n\n\n        #X_train = X_train.reshape((len(X_train), dim, 1))\n        #X_test = X_test.reshape((len(X_test), dim, 1))\n        Y_train_categorical = np_utils.to_categorical(Y_train)\n        # TRAINING\n        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n        model.fit(X_train, Y_train_categorical, batch_size=64, nb_epoch=10,shuffle=True)\n        preds = model.predict(X_test)\n        results=[]\n        for i in range(preds.shape[0]):\n            if preds[i][1] < .5:\n                results.append(0)\n            else:\n                results.append(1)\n        accuracy.append(np.mean(results == Y_test))\n    #accuracy.append(np.mean(predictions == Y_test))\n    print \"The accuracy is\", sum(accuracy)/len(accuracy)"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":72},{"cell_type":"code","source":["def getAllTeamVectors():\n    year = 2016\n    numFeatures = len(getSeasonData(1181,2012))\n    teamvecs = np.zeros(( 251, numFeatures ))\n    teams=[]\n    counter = 0\n    for team in teamList:\n        team_id = teams_pd[teams_pd['Team_Name'] == team].values[0][0]\n        team_vector = getSeasonData(team_id, year)\n        if (team_vector[0] == 0 or team_vector[4] == 0):\n            continue\n        teamvecs[counter] = team_vector\n        teams.append(team)\n        counter += 1\n    team = pd.np.array(teams)\n    team = np.reshape(team, (team.shape[0], 1))\n    with open(\"allNames.tsv\", \"wb\") as f:\n        writer = csv.writer(f, delimiter='\\t')\n        writer.writerows(team)\n    with open(\"allVecs.tsv\", \"wb\") as f:\n        writer = csv.writer(f, delimiter='\\t')\n        writer.writerows(teamvecs)\ngetAllTeamVectors()"],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":73},{"cell_type":"markdown","source":["Below is some hyperparameter optimization code."],"metadata":{}},{"cell_type":"code","source":["# with SVC\n#from utils import *\n#from sklearn.svm import LinearSVC\n#import time\n# split into training and testing data\n#X_train, X_test, y_train, y_test = train_test_split(xTrain, yTrain, test_size = 0.20)\n\n# create basic classifier with hardcoded hyperparams\n#linear_svm = LinearSVC(penalty='l2', loss='squared_hinge', dual=True, tol=0.0001, C=1.0) \n\n#print \"doing hyperparameter selection for linear svm\"\n#c_vals = 10.0 ** np.arange(-3, 3)\n#best = {'train error': np.inf, 'test error': np.inf, 'c':-1}\n#for c in c_vals:\n#    clf = LinearSVC(penalty='l2', loss='squared_hinge', dual=True, tol=0.0001, C=c)\n#    print \"training with c = {}\".format(c)\n#    train_err, test_err = cross_validate(clf, X_train, y_train) # implemented in utils.py\n#    if test_err < best['test error']:\n#        print \"found classifier with {}\".format(test_err)\n#        best['train error'] = train_err\n#        best['test error'] = test_err\n#        best['c'] = c\n#print best.items()\n    \n# rbf_SVM = SVC(C=1.0, kernel='rbf', gamma='auto')\n# print \"testing rbf fit\"\n# rbf_SVM.fit(X_train, y_train)\n# print \"rbf fit finished\"\n# linear_kernel_svm = SVC(C=1.0, kernel='linear')\n# # train all 3 and use k-fold CV to get error on X_train and X_test\n# classifiers = {'linear svm': linear_svm, 'rbf SVM': rbf_SVM}\n# err_dict = {}\n# for name, classifier in classifiers.items():\n#     print \"Doing k-fold CV with {}\".format(name)\n#     mean_train_err, mean_test_err = cross_validate(classifier, X_train, y_train) #implementation in utils.py\n#     print \"{} training error: {}, testing error: {}\".format(name, mean_train_err, mean_test_err)\n#     err_dict[name] = (mean_train_err, mean_test_err)\n# print err_dict\n\n# # grid search for hyperparameter selection\n# C_range = 10.0 ** np.arange(-3, 3)\n# g_range = 10.0 ** np.arange(-3, 3)\n\n# print \"doing hyperparameter selection for linear_kernel_svm\"\n# # hyperparameter selection for linear_kernel\n# best_so_far_linear = {'training error': np.inf, 'testing error': np.inf, 'c': -1}\n# for c in c_range:\n#     clf = SVC(C=c, kernel='linear')\n#     print \"training with c = {}\".format(c)\n#     train_err, test_err = cross_validate(clf, X_train, y_train)\n#     if test_err <= best_so_far_linear['testing error']:\n#         print \"best testing error: {}\".format(test_err)\n#         best_so_far_linear['training error'] = train_err\n#         best_so_far_linear['testing error'] = test_err\n#         best_so_far_linear['c'] = c\n        \n# print best_so_far_linear.items()\n\n# print \"doing hyperparameter selection for rbf SVM\"\n# best_rbf = {'training error': np.inf, 'testing error': np.inf, 'c': -1, 'g': -1}\n# for c in c_range:\n#     for g in g_range:\n#         clf = SVC(C=c, kernel='rbf', gamma=g)\n#         print \"training rbf svm with c = {}, g = {}\".format(c, g)\n#         train_err, test_err = cross_validate(clf, X_train, y_train)\n#         if test_err <= best_rbf['testing error']:\n#             print \"best testing error: {}\".format(test_err)\n#             best_rbf['training error'] = train_err\n#             best_rbf['testing error'] = test_err\n#             best_rbf['c'] = c\n#             best_rbf['g'] = g\n# print best_rbf.items()\n        "],"metadata":{"collapsed":false,"deletable":true,"editable":true},"outputs":[],"execution_count":75},{"cell_type":"code","source":[""],"metadata":{"collapsed":true},"outputs":[],"execution_count":76}],"metadata":{"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython2","codemirror_mode":{"name":"ipython","version":2},"version":"2.7.12","nbconvert_exporter":"python","file_extension":".py"},"name":"March Madness (1)","notebookId":3766048679895188,"kernelspec":{"display_name":"Python [default]","language":"python","name":"python2"},"anaconda-cloud":{}},"nbformat":4,"nbformat_minor":0}
