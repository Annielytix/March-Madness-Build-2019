{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I published a [blog post](https://adeshpande3.github.io/adeshpande3.github.io/Applying-Machine-Learning-to-March-Madness) detailing the general machine learning pipeline, so check that out as look at the code in this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start off with a bunch of different imports. A lot of these come from Scikit Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from __future__ import division\n",
    "import collections\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Convolution1D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from keras.utils import np_utils\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import sys\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import math\n",
    "import csv\n",
    "%matplotlib inline\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import urllib\n",
    "from sklearn.svm import LinearSVC\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Visualizing All the Historical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's first take a look at all the historical data we have. These are stats from the 1985 - 2016 NCAA basketball seasons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Daynum</th>\n",
       "      <th>Wteam</th>\n",
       "      <th>Wscore</th>\n",
       "      <th>Lteam</th>\n",
       "      <th>Lscore</th>\n",
       "      <th>Wloc</th>\n",
       "      <th>Numot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1985</td>\n",
       "      <td>20</td>\n",
       "      <td>1228</td>\n",
       "      <td>81</td>\n",
       "      <td>1328</td>\n",
       "      <td>64</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1985</td>\n",
       "      <td>25</td>\n",
       "      <td>1106</td>\n",
       "      <td>77</td>\n",
       "      <td>1354</td>\n",
       "      <td>70</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1985</td>\n",
       "      <td>25</td>\n",
       "      <td>1112</td>\n",
       "      <td>63</td>\n",
       "      <td>1223</td>\n",
       "      <td>56</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1985</td>\n",
       "      <td>25</td>\n",
       "      <td>1165</td>\n",
       "      <td>70</td>\n",
       "      <td>1432</td>\n",
       "      <td>54</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1985</td>\n",
       "      <td>25</td>\n",
       "      <td>1192</td>\n",
       "      <td>86</td>\n",
       "      <td>1447</td>\n",
       "      <td>74</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  Daynum  Wteam  Wscore  Lteam  Lscore Wloc  Numot\n",
       "0    1985      20   1228      81   1328      64    N      0\n",
       "1    1985      25   1106      77   1354      70    H      0\n",
       "2    1985      25   1112      63   1223      56    H      0\n",
       "3    1985      25   1165      70   1432      54    H      0\n",
       "4    1985      25   1192      86   1447      74    H      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This one contains stats for every single regular season game played between 1985 and 2015. It mainly\n",
    "# contains info on the score of the game, the IDs for each team, and where the game was played.\n",
    "reg_season_compact_pd = pd.read_csv('Data/RegularSeasonCompactResults.csv')\n",
    "reg_season_compact_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Season', u'Daynum', u'Wteam', u'Wscore', u'Lteam', u'Lscore', u'Wloc',\n",
       "       u'Numot', u'Wfgm', u'Wfga', u'Wfgm3', u'Wfga3', u'Wftm', u'Wfta',\n",
       "       u'Wor', u'Wdr', u'Wast', u'Wto', u'Wstl', u'Wblk', u'Wpf', u'Lfgm',\n",
       "       u'Lfga', u'Lfgm3', u'Lfga3', u'Lftm', u'Lfta', u'Lor', u'Ldr', u'Last',\n",
       "       u'Lto', u'Lstl', u'Lblk', u'Lpf'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This one expands on the previous data frame by going into more in depth stats like 3 point field goals,\n",
    "# free throws, steals, blocks, etc. \n",
    "reg_season_detailed_pd = pd.read_csv('Data/RegularSeasonDetailedResults.csv')\n",
    "reg_season_detailed_pd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Dayzero</th>\n",
       "      <th>Regionw</th>\n",
       "      <th>Regionx</th>\n",
       "      <th>Regiony</th>\n",
       "      <th>Regionz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1985</td>\n",
       "      <td>10/29/1984</td>\n",
       "      <td>East</td>\n",
       "      <td>West</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Southeast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1986</td>\n",
       "      <td>10/28/1985</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Southeast</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1987</td>\n",
       "      <td>10/27/1986</td>\n",
       "      <td>East</td>\n",
       "      <td>Southeast</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1988</td>\n",
       "      <td>11/2/1987</td>\n",
       "      <td>East</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Southeast</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1989</td>\n",
       "      <td>10/31/1988</td>\n",
       "      <td>East</td>\n",
       "      <td>West</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>Southeast</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season     Dayzero Regionw    Regionx    Regiony    Regionz\n",
       "0    1985  10/29/1984    East       West    Midwest  Southeast\n",
       "1    1986  10/28/1985    East    Midwest  Southeast       West\n",
       "2    1987  10/27/1986    East  Southeast    Midwest       West\n",
       "3    1988   11/2/1987    East    Midwest  Southeast       West\n",
       "4    1989  10/31/1988    East       West    Midwest  Southeast"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Don't think this data is honestly that important. Just contains the region areas for the tournament each \n",
    "# year. There isn't really a distinct \"home field\" advantage in the tourney because the games are supposed\n",
    "# to be on neutral sites. \n",
    "seasons_pd = pd.read_csv('Data/Seasons.csv')\n",
    "seasons_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team_Id</th>\n",
       "      <th>Team_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>1460</td>\n",
       "      <td>Wright St</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>1461</td>\n",
       "      <td>Wyoming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>1462</td>\n",
       "      <td>Xavier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>1463</td>\n",
       "      <td>Yale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>1464</td>\n",
       "      <td>Youngstown St</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Team_Id      Team_Name\n",
       "359     1460      Wright St\n",
       "360     1461        Wyoming\n",
       "361     1462         Xavier\n",
       "362     1463           Yale\n",
       "363     1464  Youngstown St"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teams_pd = pd.read_csv('Data/Teams.csv')\n",
    "teamList = teams_pd['Team_Name'].tolist()\n",
    "teams_pd.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Team_Id Team_Name\n",
      "141     1242    Kansas\n"
     ]
    }
   ],
   "source": [
    "# Print Kansas because Frank Mason is hella good\n",
    "print teams_pd[teams_pd['Team_Name'] == 'Kansas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Team_Id Team_Name\n",
      "316     1417      UCLA\n"
     ]
    }
   ],
   "source": [
    "# Jk, Lonzo > Mason\n",
    "print teams_pd[teams_pd['Team_Name'] == 'UCLA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Daynum</th>\n",
       "      <th>Wteam</th>\n",
       "      <th>Wscore</th>\n",
       "      <th>Lteam</th>\n",
       "      <th>Lscore</th>\n",
       "      <th>Wloc</th>\n",
       "      <th>Numot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1985</td>\n",
       "      <td>136</td>\n",
       "      <td>1116</td>\n",
       "      <td>63</td>\n",
       "      <td>1234</td>\n",
       "      <td>54</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1985</td>\n",
       "      <td>136</td>\n",
       "      <td>1120</td>\n",
       "      <td>59</td>\n",
       "      <td>1345</td>\n",
       "      <td>58</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1985</td>\n",
       "      <td>136</td>\n",
       "      <td>1207</td>\n",
       "      <td>68</td>\n",
       "      <td>1250</td>\n",
       "      <td>43</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1985</td>\n",
       "      <td>136</td>\n",
       "      <td>1229</td>\n",
       "      <td>58</td>\n",
       "      <td>1425</td>\n",
       "      <td>55</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1985</td>\n",
       "      <td>136</td>\n",
       "      <td>1242</td>\n",
       "      <td>49</td>\n",
       "      <td>1325</td>\n",
       "      <td>38</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  Daynum  Wteam  Wscore  Lteam  Lscore Wloc  Numot\n",
       "0    1985     136   1116      63   1234      54    N      0\n",
       "1    1985     136   1120      59   1345      58    N      0\n",
       "2    1985     136   1207      68   1250      43    N      0\n",
       "3    1985     136   1229      58   1425      55    N      0\n",
       "4    1985     136   1242      49   1325      38    N      0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This one contains the stats for every single NCAA tournament game from 1985 to 2015\n",
    "tourney_compact_pd = pd.read_csv('Data/TourneyCompactResults.csv')\n",
    "tourney_compact_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Daynum</th>\n",
       "      <th>Wteam</th>\n",
       "      <th>Wscore</th>\n",
       "      <th>Lteam</th>\n",
       "      <th>Lscore</th>\n",
       "      <th>Wloc</th>\n",
       "      <th>Numot</th>\n",
       "      <th>Wfgm</th>\n",
       "      <th>Wfga</th>\n",
       "      <th>...</th>\n",
       "      <th>Lfga3</th>\n",
       "      <th>Lftm</th>\n",
       "      <th>Lfta</th>\n",
       "      <th>Lor</th>\n",
       "      <th>Ldr</th>\n",
       "      <th>Last</th>\n",
       "      <th>Lto</th>\n",
       "      <th>Lstl</th>\n",
       "      <th>Lblk</th>\n",
       "      <th>Lpf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003</td>\n",
       "      <td>134</td>\n",
       "      <td>1421</td>\n",
       "      <td>92</td>\n",
       "      <td>1411</td>\n",
       "      <td>84</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>69</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>17</td>\n",
       "      <td>28</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003</td>\n",
       "      <td>136</td>\n",
       "      <td>1112</td>\n",
       "      <td>80</td>\n",
       "      <td>1436</td>\n",
       "      <td>51</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>136</td>\n",
       "      <td>1113</td>\n",
       "      <td>84</td>\n",
       "      <td>1272</td>\n",
       "      <td>71</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>136</td>\n",
       "      <td>1141</td>\n",
       "      <td>79</td>\n",
       "      <td>1166</td>\n",
       "      <td>73</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003</td>\n",
       "      <td>136</td>\n",
       "      <td>1143</td>\n",
       "      <td>76</td>\n",
       "      <td>1301</td>\n",
       "      <td>74</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  Daynum  Wteam  Wscore  Lteam  Lscore Wloc  Numot  Wfgm  Wfga ...   \\\n",
       "0    2003     134   1421      92   1411      84    N      1    32    69 ...    \n",
       "1    2003     136   1112      80   1436      51    N      0    31    66 ...    \n",
       "2    2003     136   1113      84   1272      71    N      0    31    59 ...    \n",
       "3    2003     136   1141      79   1166      73    N      0    29    53 ...    \n",
       "4    2003     136   1143      76   1301      74    N      1    27    64 ...    \n",
       "\n",
       "   Lfga3  Lftm  Lfta  Lor  Ldr  Last  Lto  Lstl  Lblk  Lpf  \n",
       "0     31    14    31   17   28    16   15     5     0   22  \n",
       "1     16     7     7    8   26    12   17    10     3   15  \n",
       "2     28    14    21   20   22    11   12     2     5   18  \n",
       "3     17    12    17   14   17    20   21     6     6   21  \n",
       "4     21    15    20   10   26    16   14     5     8   19  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# More deatiled tourney stats (except only stats from 2003 :( )\n",
    "tourney_detailed_pd = pd.read_csv('Data/TourneyDetailedResults.csv')\n",
    "tourney_detailed_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1985</td>\n",
       "      <td>W01</td>\n",
       "      <td>1207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1985</td>\n",
       "      <td>W02</td>\n",
       "      <td>1210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1985</td>\n",
       "      <td>W03</td>\n",
       "      <td>1228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1985</td>\n",
       "      <td>W04</td>\n",
       "      <td>1260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1985</td>\n",
       "      <td>W05</td>\n",
       "      <td>1374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season Seed  Team\n",
       "0    1985  W01  1207\n",
       "1    1985  W02  1210\n",
       "2    1985  W03  1228\n",
       "3    1985  W04  1260\n",
       "4    1985  W05  1374"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This one tells you what seed each team was for a given tournament year\n",
    "tourney_seeds_pd = pd.read_csv('Data/TourneySeeds.csv')\n",
    "tourney_seeds_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1985</td>\n",
       "      <td>Y03</td>\n",
       "      <td>1181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1986</td>\n",
       "      <td>W01</td>\n",
       "      <td>1181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>1987</td>\n",
       "      <td>Y05</td>\n",
       "      <td>1181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>1988</td>\n",
       "      <td>W02</td>\n",
       "      <td>1181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>1989</td>\n",
       "      <td>W02</td>\n",
       "      <td>1181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>1990</td>\n",
       "      <td>W03</td>\n",
       "      <td>1181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1991</td>\n",
       "      <td>Y02</td>\n",
       "      <td>1181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>1992</td>\n",
       "      <td>W01</td>\n",
       "      <td>1181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>1993</td>\n",
       "      <td>X03</td>\n",
       "      <td>1181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>1994</td>\n",
       "      <td>X02</td>\n",
       "      <td>1181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>1996</td>\n",
       "      <td>Y08</td>\n",
       "      <td>1181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>1997</td>\n",
       "      <td>X02</td>\n",
       "      <td>1181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>1998</td>\n",
       "      <td>Z01</td>\n",
       "      <td>1181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>1999</td>\n",
       "      <td>W01</td>\n",
       "      <td>1181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>2000</td>\n",
       "      <td>W01</td>\n",
       "      <td>1181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>2001</td>\n",
       "      <td>W01</td>\n",
       "      <td>1181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>2002</td>\n",
       "      <td>Y01</td>\n",
       "      <td>1181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>2003</td>\n",
       "      <td>Z03</td>\n",
       "      <td>1181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>2004</td>\n",
       "      <td>W01</td>\n",
       "      <td>1181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>2005</td>\n",
       "      <td>Y01</td>\n",
       "      <td>1181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>2006</td>\n",
       "      <td>W01</td>\n",
       "      <td>1181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>2007</td>\n",
       "      <td>Z06</td>\n",
       "      <td>1181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>2008</td>\n",
       "      <td>Z02</td>\n",
       "      <td>1181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>2009</td>\n",
       "      <td>W02</td>\n",
       "      <td>1181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1625</th>\n",
       "      <td>2010</td>\n",
       "      <td>X01</td>\n",
       "      <td>1181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1692</th>\n",
       "      <td>2011</td>\n",
       "      <td>X01</td>\n",
       "      <td>1181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>2012</td>\n",
       "      <td>Y02</td>\n",
       "      <td>1181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1844</th>\n",
       "      <td>2013</td>\n",
       "      <td>Y02</td>\n",
       "      <td>1181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1913</th>\n",
       "      <td>2014</td>\n",
       "      <td>Y03</td>\n",
       "      <td>1181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963</th>\n",
       "      <td>2015</td>\n",
       "      <td>X01</td>\n",
       "      <td>1181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068</th>\n",
       "      <td>2016</td>\n",
       "      <td>Z04</td>\n",
       "      <td>1181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Season Seed  Team\n",
       "34      1985  Y03  1181\n",
       "64      1986  W01  1181\n",
       "164     1987  Y05  1181\n",
       "193     1988  W02  1181\n",
       "257     1989  W02  1181\n",
       "322     1990  W03  1181\n",
       "417     1991  Y02  1181\n",
       "448     1992  W01  1181\n",
       "530     1993  X03  1181\n",
       "593     1994  X02  1181\n",
       "743     1996  Y08  1181\n",
       "785     1997  X02  1181\n",
       "880     1998  Z01  1181\n",
       "896     1999  W01  1181\n",
       "960     2000  W01  1181\n",
       "1024    2001  W01  1181\n",
       "1122    2002  Y01  1181\n",
       "1205    2003  Z03  1181\n",
       "1219    2004  W01  1181\n",
       "1316    2005  Y01  1181\n",
       "1349    2006  W01  1181\n",
       "1467    2007  Z06  1181\n",
       "1529    2008  Z02  1181\n",
       "1545    2009  W02  1181\n",
       "1625    2010  X01  1181\n",
       "1692    2011  X01  1181\n",
       "1777    2012  Y02  1181\n",
       "1844    2013  Y02  1181\n",
       "1913    2014  Y03  1181\n",
       "1963    2015  X01  1181\n",
       "2068    2016  Z04  1181"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seeing what seed Duke was in every tourney\n",
    "duke_id = teams_pd[teams_pd['Team_Name'] == 'Duke'].values[0][0]\n",
    "tourney_seeds_pd[tourney_seeds_pd['Team'] == duke_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Slot</th>\n",
       "      <th>Strongseed</th>\n",
       "      <th>Weakseed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1985</td>\n",
       "      <td>R1W1</td>\n",
       "      <td>W01</td>\n",
       "      <td>W16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1985</td>\n",
       "      <td>R1W2</td>\n",
       "      <td>W02</td>\n",
       "      <td>W15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1985</td>\n",
       "      <td>R1W3</td>\n",
       "      <td>W03</td>\n",
       "      <td>W14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1985</td>\n",
       "      <td>R1W4</td>\n",
       "      <td>W04</td>\n",
       "      <td>W13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1985</td>\n",
       "      <td>R1W5</td>\n",
       "      <td>W05</td>\n",
       "      <td>W12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  Slot Strongseed Weakseed\n",
       "0    1985  R1W1        W01      W16\n",
       "1    1985  R1W2        W02      W15\n",
       "2    1985  R1W3        W03      W14\n",
       "3    1985  R1W4        W04      W13\n",
       "4    1985  R1W5        W05      W12"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Don't know how helpful this is tbh, because it just tells you what the seeds of the stronger\n",
    "# and weaker seeds are (assuming that the favored team wins??), so its always 1 vs 16 and then \n",
    "# 1 vs 8 and 1 vs 4..\n",
    "tourney_slots_pd = pd.read_csv('Data/TourneySlots.csv')\n",
    "tourney_slots_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Conference</th>\n",
       "      <th>Schls</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>W-L%</th>\n",
       "      <th>SRS</th>\n",
       "      <th>SOS</th>\n",
       "      <th>AP</th>\n",
       "      <th>NCAA</th>\n",
       "      <th>FF</th>\n",
       "      <th>Regular Season Champ</th>\n",
       "      <th>Tournament Champ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003</td>\n",
       "      <td>Southeastern Conference</td>\n",
       "      <td>12</td>\n",
       "      <td>220</td>\n",
       "      <td>145</td>\n",
       "      <td>0.603</td>\n",
       "      <td>12.95</td>\n",
       "      <td>8.58</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Kentucky (East) Mississippi St (West)</td>\n",
       "      <td>Kentucky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003</td>\n",
       "      <td>Big 12 Conference</td>\n",
       "      <td>12</td>\n",
       "      <td>238</td>\n",
       "      <td>146</td>\n",
       "      <td>0.620</td>\n",
       "      <td>12.94</td>\n",
       "      <td>8.21</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>Oklahoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>Atlantic Coast Conference</td>\n",
       "      <td>9</td>\n",
       "      <td>170</td>\n",
       "      <td>111</td>\n",
       "      <td>0.605</td>\n",
       "      <td>12.75</td>\n",
       "      <td>7.83</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Wake Forest</td>\n",
       "      <td>Duke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>Big East Conference</td>\n",
       "      <td>14</td>\n",
       "      <td>262</td>\n",
       "      <td>179</td>\n",
       "      <td>0.594</td>\n",
       "      <td>11.03</td>\n",
       "      <td>7.13</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Boston College (East) Connecticut (East) Pitts...</td>\n",
       "      <td>Pittsburgh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003</td>\n",
       "      <td>Big Ten Conference</td>\n",
       "      <td>11</td>\n",
       "      <td>200</td>\n",
       "      <td>146</td>\n",
       "      <td>0.578</td>\n",
       "      <td>10.68</td>\n",
       "      <td>7.66</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Illinois</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year                 Conference  Schls    W    L   W-L%    SRS   SOS  AP  \\\n",
       "0  2003    Southeastern Conference     12  220  145  0.603  12.95  8.58   4   \n",
       "1  2003          Big 12 Conference     12  238  146  0.620  12.94  8.21   4   \n",
       "2  2003  Atlantic Coast Conference      9  170  111  0.605  12.75  7.83   3   \n",
       "3  2003        Big East Conference     14  262  179  0.594  11.03  7.13   4   \n",
       "4  2003         Big Ten Conference     11  200  146  0.578  10.68  7.66   2   \n",
       "\n",
       "   NCAA  FF                               Regular Season Champ  \\\n",
       "0     6   0              Kentucky (East) Mississippi St (West)   \n",
       "1     6   2                                             Kansas   \n",
       "2     4   0                                        Wake Forest   \n",
       "3     4   1  Boston College (East) Connecticut (East) Pitts...   \n",
       "4     5   0                                          Wisconsin   \n",
       "\n",
       "  Tournament Champ  \n",
       "0         Kentucky  \n",
       "1         Oklahoma  \n",
       "2             Duke  \n",
       "3       Pittsburgh  \n",
       "4         Illinois  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conference_pd = pd.read_csv('Data/Conference.csv')\n",
    "conference_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tourney_results_pd = pd.read_csv('Data/TourneyResults.csv')\n",
    "tourney_results_pd.head()\n",
    "NCAAChampionsList = tourney_results_pd['NCAA Champion'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's make this supervised trianing problem where our model with take in 2 d dimensional vectors, representing the two teams playing in the tournament. Each d dimensional vector will contain information about the team for that year. Below are the features we end up using. \n",
    "\n",
    "* Regular Season Wins \n",
    "* Points per game season average \n",
    "* Points per game allowed season average\n",
    "* Whether or not in Power 6 conference (ACC, Big Ten, Big 12, SEC, Pac 12, Big East) - Binary label\n",
    "* Number of 3's per game\n",
    "* Turnovers per game average\n",
    "* Assists per game average\n",
    "* Conference Championship - binary label\n",
    "* Conference Tournament Championship - binary label\n",
    "* Tournament Seed\n",
    "* Strength of Schedule\n",
    "* Simple Rating System\n",
    "* Rebounds per game average\n",
    "* Steals per game average\n",
    "* Number of NCAA appearances since 1985\n",
    "* Whether the team is home or away or neutral (labels -1, 0, and 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Functions To Help Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "These functions help us obtain all the information that will eventually go in our team vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "listACCteams = ['North Carolina','Virginia','Florida St','Louisville','Notre Dame','Syracuse','Duke','Virginia Tech','Georgia Tech','Miami','Wake Forest','Clemson','NC State','Boston College','Pittsburgh']\n",
    "listPac12teams = ['Arizona','Oregon','UCLA','California','USC','Utah','Washington St','Stanford','Arizona St','Colorado','Washington','Oregon St']\n",
    "listSECteams = ['Kentucky','South Carolina','Florida','Arkansas','Alabama','Tennessee','Mississippi St','Georgia','Ole Miss','Vanderbilt','Auburn','Texas A&M','LSU','Missouri']\n",
    "listBig10teams = ['Maryland','Wisconsin','Purdue','Northwestern','Michigan St','Indiana','Iowa','Michigan','Penn St','Nebraska','Minnesota','Illinois','Ohio St','Rutgers']\n",
    "listBig12teams = ['Kansas','Baylor','West Virginia','Iowa St','TCU','Kansas St','Texas Tech','Oklahoma St','Texas','Oklahoma']\n",
    "listBigEastteams = ['Butler','Creighton','DePaul','Georgetown','Marquette','Providence','Seton Hall','St John\\'s','Villanova','Xavier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def checkPower6Conference(team_id):\n",
    "    teamName = teams_pd.values[team_id-1101][1]\n",
    "    if (teamName in listACCteams or teamName in listBig10teams or teamName in listBig12teams\n",
    "       or teamName in listSECteams or teamName in listPac12teams or teamName in listBigEastteams):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def getTeamID(name):\n",
    "    return teams_pd[teams_pd['Team_Name'] == name].values[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def getTeamName(team_id):\n",
    "    return teams_pd[teams_pd['Team_Id'] == team_id].values[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def getNumChampionships(team_id):\n",
    "    name = getTeamName(team_id)\n",
    "    return NCAAChampionsList.count(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def getListForURL(team_list):\n",
    "    team_list = [x.lower() for x in team_list]\n",
    "    team_list = [t.replace(' ', '-') for t in team_list]\n",
    "    team_list = [t.replace('st', 'state') for t in team_list]\n",
    "    team_list = [t.replace('northern-dakota', 'north-dakota') for t in team_list]\n",
    "    team_list = [t.replace('nc-', 'north-carolina-') for t in team_list]\n",
    "    team_list = [t.replace('fl-', 'florida-') for t in team_list]\n",
    "    team_list = [t.replace('ga-', 'georgia-') for t in team_list]\n",
    "    team_list = [t.replace('lsu', 'louisiana-state') for t in team_list]\n",
    "    team_list = [t.replace('maristate', 'marist') for t in team_list]\n",
    "    team_list = [t.replace('stateate', 'state') for t in team_list]\n",
    "    team_list = [t.replace('northernorthern', 'northern') for t in team_list]\n",
    "    team_list = [t.replace('usc', 'southern-california') for t in team_list]\n",
    "    base = 'http://www.sports-reference.com/cbb/schools/'\n",
    "    for team in team_list:\n",
    "        url = base + team + '/'\n",
    "getListForURL(teamList);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Function for handling the annoying cases of Florida and FL, as well as State and St\n",
    "def handleCases(arr):\n",
    "    indices = []\n",
    "    listLen = len(arr)\n",
    "    for i in range(listLen):\n",
    "        if (arr[i] == 'St' or arr[i] == 'FL'):\n",
    "            indices.append(i)\n",
    "    for p in indices:\n",
    "        arr[p-1] = arr[p-1] + ' ' + arr[p]\n",
    "    for i in range(len(indices)): \n",
    "        arr.remove(arr[indices[i] - i])\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def checkConferenceChamp(team_id, year):\n",
    "    year_conf_pd = conference_pd[conference_pd['Year'] == year]\n",
    "    champs = year_conf_pd['Regular Season Champ'].tolist()\n",
    "    # For handling cases where there is more than one champion\n",
    "    champs_separated = [words for segments in champs for words in segments.split()]\n",
    "    name = getTeamName(team_id)\n",
    "    champs_separated = handleCases(champs_separated)\n",
    "    if (name in champs_separated):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def checkConferenceTourneyChamp(team_id, year):\n",
    "    year_conf_pd = conference_pd[conference_pd['Year'] == year]\n",
    "    champs = year_conf_pd['Tournament Champ'].tolist()\n",
    "    name = getTeamName(team_id)\n",
    "    if (name in champs):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def getTourneyAppearances(team_id):\n",
    "    return len(tourney_seeds_pd[tourney_seeds_pd['Team'] == team_id].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def handleDifferentCSV(df):\n",
    "    # The stats CSV is a lit different in terms of naming so below is just some data cleaning\n",
    "    df['School'] = df['School'].replace('(State)', 'St', regex=True) \n",
    "    df['School'] = df['School'].replace('Albany (NY)', 'Albany NY') \n",
    "    df['School'] = df['School'].replace('Boston University', 'Boston Univ')\n",
    "    df['School'] = df['School'].replace('Central Michigan', 'C Michigan')\n",
    "    df['School'] = df['School'].replace('(Eastern)', 'E', regex=True)\n",
    "    df['School'] = df['School'].replace('Louisiana St', 'LSU')\n",
    "    df['School'] = df['School'].replace('North Carolina St', 'NC State')\n",
    "    df['School'] = df['School'].replace('Southern California', 'USC')\n",
    "    df['School'] = df['School'].replace('University of California', 'California', regex=True) \n",
    "    df['School'] = df['School'].replace('American', 'American Univ')\n",
    "    df['School'] = df['School'].replace('Arkansas-Little Rock', 'Ark Little Rock')\n",
    "    df['School'] = df['School'].replace('Arkansas-Pine Bluff', 'Ark Pine Bluff')\n",
    "    df['School'] = df['School'].replace('Bowling Green St', 'Bowling Green')\n",
    "    df['School'] = df['School'].replace('Brigham Young', 'BYU')\n",
    "    df['School'] = df['School'].replace('Cal Poly', 'Cal Poly SLO')\n",
    "    df['School'] = df['School'].replace('Centenary (LA)', 'Centenary')\n",
    "    df['School'] = df['School'].replace('Central Connecticut St', 'Central Conn')\n",
    "    df['School'] = df['School'].replace('Charleston Southern', 'Charleston So')\n",
    "    df['School'] = df['School'].replace('Coastal Carolina', 'Coastal Car')\n",
    "    df['School'] = df['School'].replace('College of Charleston', 'Col Charleston')\n",
    "    df['School'] = df['School'].replace('Cal St Fullerton', 'CS Fullerton')\n",
    "    df['School'] = df['School'].replace('Cal St Sacramento', 'CS Sacramento')\n",
    "    df['School'] = df['School'].replace('Cal St Bakersfield', 'CS Bakersfield')\n",
    "    df['School'] = df['School'].replace('Cal St Northridge', 'CS Northridge')\n",
    "    df['School'] = df['School'].replace('East Tennessee St', 'ETSU')\n",
    "    df['School'] = df['School'].replace('Detroit Mercy', 'Detroit')\n",
    "    df['School'] = df['School'].replace('Fairleigh Dickinson', 'F Dickinson')\n",
    "    df['School'] = df['School'].replace('Florida Atlantic', 'FL Atlantic')\n",
    "    df['School'] = df['School'].replace('Florida Gulf Coast', 'FL Gulf Coast')\n",
    "    df['School'] = df['School'].replace('Florida International', 'Florida Intl')\n",
    "    df['School'] = df['School'].replace('George Washington', 'G Washington')\n",
    "    df['School'] = df['School'].replace('Georgia Southern', 'Ga Southern')\n",
    "    df['School'] = df['School'].replace('Gardner-Webb', 'Gardner Webb')\n",
    "    df['School'] = df['School'].replace('Illinois-Chicago', 'IL Chicago')\n",
    "    df['School'] = df['School'].replace('Kent St', 'Kent')\n",
    "    df['School'] = df['School'].replace('Long Island University', 'Long Island')\n",
    "    df['School'] = df['School'].replace('Loyola Marymount', 'Loy Marymount')\n",
    "    df['School'] = df['School'].replace('Loyola (MD)', 'Loyola MD')\n",
    "    df['School'] = df['School'].replace('Loyola (IL)', 'Loyola-Chicago')\n",
    "    df['School'] = df['School'].replace('Massachusetts', 'MA Lowell')\n",
    "    df['School'] = df['School'].replace('Maryland-Eastern Shore', 'MD E Shore')\n",
    "    df['School'] = df['School'].replace('Miami (FL)', 'Miami FL')\n",
    "    df['School'] = df['School'].replace('Miami (OH)', 'Miami OH')\n",
    "    df['School'] = df['School'].replace('Missouri-Kansas City', 'Missouri KC')\n",
    "    df['School'] = df['School'].replace('Monmouth', 'Monmouth NJ')\n",
    "    df['School'] = df['School'].replace('Mississippi Valley St', 'MS Valley St')\n",
    "    df['School'] = df['School'].replace('Montana St', 'MTSU')\n",
    "    df['School'] = df['School'].replace('Northern Colorado', 'N Colorado')\n",
    "    df['School'] = df['School'].replace('North Dakota St', 'N Dakota St')\n",
    "    df['School'] = df['School'].replace('Northern Illinois', 'N Illinois')\n",
    "    df['School'] = df['School'].replace('Northern Kentucky', 'N Kentucky')\n",
    "    df['School'] = df['School'].replace('North Carolina A&T', 'NC A&T')\n",
    "    df['School'] = df['School'].replace('North Carolina Central', 'NC Central')\n",
    "    df['School'] = df['School'].replace('Pennsylvania', 'Penn')\n",
    "    df['School'] = df['School'].replace('South Carolina St', 'S Carolina St')\n",
    "    df['School'] = df['School'].replace('Southern Illinois', 'S Illinois')\n",
    "    df['School'] = df['School'].replace('UC-Santa Barbara', 'Santa Barbara')\n",
    "    df['School'] = df['School'].replace('Southeastern Louisiana', 'SE Louisiana')\n",
    "    df['School'] = df['School'].replace('Southeast Missouri St', 'SE Missouri St')\n",
    "    df['School'] = df['School'].replace('Stephen F. Austin', 'SF Austin')\n",
    "    df['School'] = df['School'].replace('Southern Methodist', 'SMU')\n",
    "    df['School'] = df['School'].replace('Southern Mississippi', 'Southern Miss')\n",
    "    df['School'] = df['School'].replace('Southern', 'Southern Univ')\n",
    "    df['School'] = df['School'].replace('St. Bonaventure', 'St Bonaventure')\n",
    "    df['School'] = df['School'].replace('St. Francis (NY)', 'St Francis NY')\n",
    "    df['School'] = df['School'].replace('Saint Francis (PA)', 'St Francis PA')\n",
    "    df['School'] = df['School'].replace('St. John\\'s (NY)', 'St John\\'s')\n",
    "    df['School'] = df['School'].replace('Saint Joseph\\'s', 'St Joseph\\'s PA')\n",
    "    df['School'] = df['School'].replace('Saint Louis', 'St Louis')\n",
    "    df['School'] = df['School'].replace('Saint Mary\\'s (CA)', 'St Mary\\'s CA')\n",
    "    df['School'] = df['School'].replace('Mount Saint Mary\\'s', 'Mt St Mary\\'s')\n",
    "    df['School'] = df['School'].replace('Saint Peter\\'s', 'St Peter\\'s')\n",
    "    df['School'] = df['School'].replace('Texas A&M-Corpus Christian', 'TAM C. Christian')\n",
    "    df['School'] = df['School'].replace('Texas Christian', 'TCU')\n",
    "    df['School'] = df['School'].replace('Tennessee-Martin', 'TN Martin')\n",
    "    df['School'] = df['School'].replace('Texas-Rio Grande Valley', 'UTRGV')\n",
    "    df['School'] = df['School'].replace('Texas Southern', 'TX Southern')\n",
    "    df['School'] = df['School'].replace('Alabama-Birmingham', 'UAB')\n",
    "    df['School'] = df['School'].replace('UC-Davis', 'UC Davis')\n",
    "    df['School'] = df['School'].replace('UC-Irvine', 'UC Irvine')\n",
    "    df['School'] = df['School'].replace('UC-Riverside', 'UC Riverside')\n",
    "    df['School'] = df['School'].replace('Central Florida', 'UCF')\n",
    "    df['School'] = df['School'].replace('Louisiana-Lafayette', 'ULL')\n",
    "    df['School'] = df['School'].replace('Louisiana-Monroe', 'ULM')\n",
    "    df['School'] = df['School'].replace('Maryland-Baltimore County', 'UMBC')\n",
    "    df['School'] = df['School'].replace('North Carolina-Asheville', 'UNC Asheville')\n",
    "    df['School'] = df['School'].replace('North Carolina-Greensboro', 'UNC Greensboro')\n",
    "    df['School'] = df['School'].replace('North Carolina-Wilmington', 'UNC Wilmington')\n",
    "    df['School'] = df['School'].replace('Nevada-Las Vegas', 'UNLV')\n",
    "    df['School'] = df['School'].replace('Texas-Arlington', 'UT Arlington')\n",
    "    df['School'] = df['School'].replace('Texas-San Antonio', 'UT San Antonio')\n",
    "    df['School'] = df['School'].replace('Texas-El Paso', 'UTEP')\n",
    "    df['School'] = df['School'].replace('Virginia Commonwealth', 'VA Commonwealth')\n",
    "    df['School'] = df['School'].replace('Western Carolina', 'W Carolina')\n",
    "    df['School'] = df['School'].replace('Western Illinois', 'W Illinois')\n",
    "    df['School'] = df['School'].replace('Western Kentucky', 'WKU')\n",
    "    df['School'] = df['School'].replace('Western Michigan', 'W Michigan')\n",
    "    df['School'] = df['School'].replace('Abilene Christian', 'Abilene Chr')\n",
    "    df['School'] = df['School'].replace('Montana State', 'Montana St')\n",
    "    df['School'] = df['School'].replace('Central Arkansas', 'Cent Arkansas')\n",
    "    df['School'] = df['School'].replace('Houston Baptist', 'Houston Bap')\n",
    "    df['School'] = df['School'].replace('South Dakota St', 'S Dakota St')\n",
    "    df['School'] = df['School'].replace('Maryland-Eastern Shore', 'MD E Shore')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Obtaining Season Vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def getSeasonData(team_id, year):\n",
    "    # The data frame below holds stats for every single game in the given year\n",
    "    year_data_pd = reg_season_compact_pd[reg_season_compact_pd['Season'] == year]\n",
    "    # Finding number of points per game\n",
    "    gamesWon = year_data_pd[year_data_pd.Wteam == team_id] \n",
    "    totalPointsScored = gamesWon['Wscore'].sum()\n",
    "    gamesLost = year_data_pd[year_data_pd.Lteam == team_id] \n",
    "    totalGames = gamesWon.append(gamesLost)\n",
    "    numGames = len(totalGames.index)\n",
    "    totalPointsScored += gamesLost['Lscore'].sum()\n",
    "    \n",
    "    # Finding number of points per game allowed\n",
    "    totalPointsAllowed = gamesWon['Lscore'].sum()\n",
    "    totalPointsAllowed += gamesLost['Wscore'].sum()\n",
    "    \n",
    "    stats_SOS_pd = pd.read_csv('Data/MMStats/MMStats_'+str(year)+'.csv')\n",
    "    stats_SOS_pd = handleDifferentCSV(stats_SOS_pd)\n",
    "    ratings_pd = pd.read_csv('Data/RatingStats/RatingStats_'+str(year)+'.csv')\n",
    "    ratings_pd = handleDifferentCSV(ratings_pd)\n",
    "    \n",
    "    name = getTeamName(team_id)\n",
    "    team = stats_SOS_pd[stats_SOS_pd['School'] == name]\n",
    "    team_rating = ratings_pd[ratings_pd['School'] == name]\n",
    "    if (len(team.index) == 0 or len(team_rating.index) == 0): #Can't find the team\n",
    "        total3sMade = 0\n",
    "        totalTurnovers = 0\n",
    "        totalAssists = 0\n",
    "        sos = 0\n",
    "        totalRebounds = 0\n",
    "        srs = 0\n",
    "        totalSteals = 0\n",
    "    else:\n",
    "        total3sMade = team['X3P'].values[0]\n",
    "        totalTurnovers = team['TOV'].values[0]\n",
    "        if (math.isnan(totalTurnovers)):\n",
    "            totalTurnovers = 0\n",
    "        totalAssists = team['AST'].values[0]\n",
    "        if (math.isnan(totalAssists)):\n",
    "            totalAssists = 0\n",
    "        sos = team['SOS'].values[0]\n",
    "        srs = team['SRS'].values[0]\n",
    "        totalRebounds = team['TRB'].values[0]\n",
    "        if (math.isnan(totalRebounds)):\n",
    "            totalRebounds = 0\n",
    "        totalSteals = team['STL'].values[0]\n",
    "        if (math.isnan(totalSteals)):\n",
    "            totalSteals = 0\n",
    "    \n",
    "    #Finding tournament seed for that year\n",
    "    tourneyYear = tourney_seeds_pd[tourney_seeds_pd['Season'] == year]\n",
    "    seed = tourneyYear[tourneyYear['Team'] == team_id]\n",
    "    if (len(seed.index) != 0):\n",
    "        seed = seed.values[0][1]\n",
    "        tournamentSeed = int(seed[1:3])\n",
    "    else:\n",
    "        tournamentSeed = 25 #Not sure how to represent if a team didn't make the tourney\n",
    "    \n",
    "    # Finding number of wins and losses\n",
    "    numWins = len(gamesWon.index)\n",
    "    # There are some teams who may have dropped to Division 2, so they won't have games \n",
    "    # a certain year. In this case, we don't want to divide by 0, so we'll just set the\n",
    "    # averages to 0 instead\n",
    "    if numGames == 0:\n",
    "        avgPointsScored = 0\n",
    "        avgPointsAllowed = 0\n",
    "        avg3sMade = 0\n",
    "        avgTurnovers = 0\n",
    "        avgAssists = 0\n",
    "        avgRebounds = 0\n",
    "        avgSteals = 0\n",
    "    else:\n",
    "        avgPointsScored = totalPointsScored/numGames\n",
    "        avgPointsAllowed = totalPointsAllowed/numGames\n",
    "        avg3sMade = total3sMade/numGames\n",
    "        avgTurnovers = totalTurnovers/numGames\n",
    "        avgAssists = totalAssists/numGames\n",
    "        avgRebounds = totalRebounds/numGames\n",
    "        avgSteals = totalSteals/numGames\n",
    "    #return [numWins, sos, srs]\n",
    "    #return [numWins, avgPointsScored, avgPointsAllowed, checkPower6Conference(team_id), avg3sMade, avg3sAllowed, avgTurnovers,\n",
    "    #        tournamentSeed, getStrengthOfSchedule(team_id, year), getTourneyAppearances(team_id)]\n",
    "    return [numWins, avgPointsScored, avgPointsAllowed, checkPower6Conference(team_id), avg3sMade, avgAssists, avgTurnovers,\n",
    "           checkConferenceChamp(team_id, year), checkConferenceTourneyChamp(team_id, year), tournamentSeed,\n",
    "            sos, srs, avgRebounds, avgSteals, getTourneyAppearances(team_id), getNumChampionships(team_id)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The following code tests out whether we can get Kentucky's season vector for 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[26,\n",
       " 79.67647058823529,\n",
       " 68.26470588235294,\n",
       " 1,\n",
       " 7.1764705882352944,\n",
       " 15.058823529411764,\n",
       " 11.823529411764707,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 8.8399999999999999,\n",
       " 20.23,\n",
       " 41.029411764705884,\n",
       " 6.0588235294117645,\n",
       " 27,\n",
       " 3]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kentucky_id = teams_pd[teams_pd['Team_Name'] == 'Kentucky'].values[0][0]\n",
    "getSeasonData(kentucky_id, 2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def compareTwoTeams(id_1, id_2, year):\n",
    "    team_1 = getSeasonData(id_1, year)\n",
    "    team_2 = getSeasonData(id_2, year)\n",
    "    diff = [a - b for a, b in zip(team_1, team_2)]\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here, we look at the difference vector between Kansas and Kentucky in 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 0.6265597147950075,\n",
       " -0.6586452762923329,\n",
       " 0,\n",
       " 2.0356506238859184,\n",
       " 3.24420677361854,\n",
       " 2.570409982174688,\n",
       " 0,\n",
       " 0,\n",
       " -3,\n",
       " 2.3800000000000008,\n",
       " 3.6400000000000006,\n",
       " 2.6978609625668426,\n",
       " 1.6078431372549025,\n",
       " 4,\n",
       " -1]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kansas_id = teams_pd[teams_pd['Team_Name'] == 'Kansas'].values[0][0]\n",
    "compareTwoTeams(kansas_id, kentucky_id, 2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This method returns the team vectors for each NCAA team for the given season. This information is held in a Python dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def createSeasonDict(year):\n",
    "    seasonDictionary = collections.defaultdict(list)\n",
    "    for team in teamList:\n",
    "        team_id = teams_pd[teams_pd['Team_Name'] == team].values[0][0]\n",
    "        team_vector = getSeasonData(team_id, year)\n",
    "        seasonDictionary[team_id] = team_vector\n",
    "    return seasonDictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def getHomeStat(row):\n",
    "    if (row == 'H'):\n",
    "        home = 1\n",
    "    if (row == 'A'):\n",
    "        home = -1\n",
    "    if (row == 'N'):\n",
    "        home = 0\n",
    "    return home"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This is the most important method, where we create our training set. The idea is that we go through each of the years that are passed in, and we obtain a season dictionary for each year (by calling the previous method). Then, we look at each game that took place over the course of the season. This data is held in the reg_season_compact_pd dataframe. This dataframe contains information about the 5,200 games that occurred. For each of these games, we take a look at the two teams playing, obtain their team vectors, and then take the difference between the two. This new resultant vector is used as a sort of \"representation\" of the differences between the 2 teams playing. This vector will be our the X (or the input) for our supervised learning problem. The Y (or the label) will be a 1 if Team 1 wins. The way we introduce negative sampling is by associating the negative of the X vector with the label of 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def createTrainingSet(years):\n",
    "    totalNumGames = 0\n",
    "    for year in years:\n",
    "        season = reg_season_compact_pd[reg_season_compact_pd['Season'] == year]\n",
    "        totalNumGames += len(season.index)\n",
    "        tourney = tourney_compact_pd[tourney_compact_pd['Season'] == year]\n",
    "        totalNumGames += len(tourney.index)\n",
    "    numFeatures = len(getSeasonData(1181,2012)) #Just choosing a random team and seeing the dimensionality of the vector\n",
    "    xTrain = np.zeros(( totalNumGames, numFeatures + 1))\n",
    "    yTrain = np.zeros(( totalNumGames ))\n",
    "    indexCounter = 0\n",
    "    for year in years:\n",
    "        team_vectors = createSeasonDict(year)\n",
    "        season = reg_season_compact_pd[reg_season_compact_pd['Season'] == year]\n",
    "        numGamesInSeason = len(season.index)\n",
    "        tourney = tourney_compact_pd[tourney_compact_pd['Season'] == year]\n",
    "        numGamesInSeason += len(tourney.index)\n",
    "        xTrainSeason = np.zeros(( numGamesInSeason, numFeatures + 1))\n",
    "        yTrainSeason = np.zeros(( numGamesInSeason ))\n",
    "        counter = 0\n",
    "        for index, row in season.iterrows():\n",
    "            w_team = row['Wteam']\n",
    "            w_vector = team_vectors[w_team]\n",
    "            l_team = row['Lteam']\n",
    "            l_vector = team_vectors[l_team]\n",
    "            diff = [a - b for a, b in zip(w_vector, l_vector)]\n",
    "            home = getHomeStat(row['Wloc'])\n",
    "            if (counter % 2 == 0):\n",
    "                diff.append(home) \n",
    "                xTrainSeason[counter] = diff\n",
    "                yTrainSeason[counter] = 1\n",
    "            else:\n",
    "                diff.append(-home)\n",
    "                xTrainSeason[counter] = [ -p for p in diff]\n",
    "                yTrainSeason[counter] = 0\n",
    "            counter += 1\n",
    "        for index, row in tourney.iterrows():\n",
    "            w_team = row['Wteam']\n",
    "            w_vector = team_vectors[w_team]\n",
    "            l_team = row['Lteam']\n",
    "            l_vector = team_vectors[l_team]\n",
    "            diff = [a - b for a, b in zip(w_vector, l_vector)]\n",
    "            home = 0 #All tournament games are neutral\n",
    "            if (counter % 2 == 0):\n",
    "                diff.append(home) \n",
    "                xTrainSeason[counter] = diff\n",
    "                yTrainSeason[counter] = 1\n",
    "            else:\n",
    "                diff.append(-home)\n",
    "                xTrainSeason[counter] = [ -p for p in diff]\n",
    "                yTrainSeason[counter] = 0\n",
    "            counter += 1\n",
    "        xTrain[indexCounter:numGamesInSeason+indexCounter] = xTrainSeason\n",
    "        yTrain[indexCounter:numGamesInSeason+indexCounter] = yTrainSeason\n",
    "        indexCounter += numGamesInSeason\n",
    "    return xTrain, yTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def normalizeInput(arr):\n",
    "    for i in range(arr.shape[1]):\n",
    "        minVal = min(arr[:,i])\n",
    "        maxVal = max(arr[:,i])\n",
    "        arr[:,i] =  (arr[:,i] - minVal) / (maxVal - minVal)\n",
    "    return arr\n",
    "# alternative:\n",
    "def normalize(X):\n",
    "    return (X - np.mean(X, axis = 0)) / np.std(X, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The code below takes a while to run, so I've commented it out right now, and you can just load in the precomputed matrices in the code block after that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "years = range(1993,2017)\n",
    "#xTrain, yTrain = createTrainingSet(years)\n",
    "#np.save('xTrain', xTrain)\n",
    "#np.save('yTrain', yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "xTrain = np.load('PrecomputedMatrices/xTrain.npy')\n",
    "yTrain = np.load('PrecomputedMatrices/yTrain.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115113, 17)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115113,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yTrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Testing Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* SVM: **72.24%**\n",
    "* Logistic Regression: **76.17%**\n",
    "* XGBoost: **76.28%**\n",
    "* Multilayered Neural Network: **76.21%**\n",
    "* Decision Tree (Classifier and/or Regressor): **65.04%**\n",
    "* Gradient Boosted Regressor (n_estimators = 100): **76.30%**\n",
    "* Linear SVC: **76.41%**\n",
    "* Random Forest Classifier (n = 200): **72.32%**\n",
    "* KNN (k = 39): **75.51%** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# These are the different models I tried. Simply uncomment the model that you want to try. \n",
    "\n",
    "#model = tree.DecisionTreeClassifier()\n",
    "#model = tree.DecisionTreeRegressor()\n",
    "#model = linear_model.LogisticRegression()\n",
    "model = linear_model.BayesianRidge()\n",
    "#model = linear_model.Lasso()\n",
    "#model = svm.SVC()\n",
    "#model = svm.SVR()\n",
    "#model = linear_model.Ridge(alpha = 0.5)\n",
    "#model = AdaBoostClassifier(n_estimators=100)\n",
    "#model = GradientBoostingClassifier(n_estimators=100)\n",
    "#model = GradientBoostingRegressor(n_estimators=100, max_depth=5)\n",
    "#model = RandomForestClassifier(n_estimators=64)\n",
    "#model = KNeighborsClassifier(n_neighbors=39)\n",
    "#neuralNetwork(10)\n",
    "#model = VotingClassifier(estimators=[('GBR', model1), ('BR', model2), ('KNN', model3)], voting='soft')\n",
    "#model = LinearSVC(penalty='l2', loss='squared_hinge', dual=True, tol=0.0001, C=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def showDependency(predictions, test, stat, my_categories):\n",
    "    difference = test[:,my_categories.index(stat)]\n",
    "    plt.scatter(difference, predictions)\n",
    "    plt.ylabel('Probability of Team 1 Win')\n",
    "    plt.xlabel(stat + ' Difference (Team 1 - Team 2)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def showFeatureImportance(my_categories):\n",
    "    fx_imp = pd.Series(model.feature_importances_, index=my_categories)\n",
    "    fx_imp /= fx_imp.max()\n",
    "    fx_imp.sort()\n",
    "    fx_imp.plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished iteration: 0\n",
      "The accuracy is 0.760311338128\n"
     ]
    }
   ],
   "source": [
    "categories=['Wins','PPG','PPGA','PowerConf','3PG', 'APG','TOP','Conference Champ','Tourney Conference Champ',\n",
    "           'Seed','SOS','SRS', 'RPG', 'SPG', 'Tourney Appearances','National Championships','Location']\n",
    "accuracy=[]\n",
    "\n",
    "for i in range(1):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(xTrain, yTrain)\n",
    "    results = model.fit(X_train, Y_train)\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    preds[preds < .5] = 0\n",
    "    preds[preds >= .5] = 1\n",
    "    accuracy.append(np.mean(preds == Y_test))\n",
    "    #accuracy.append(np.mean(predictions == Y_test))\n",
    "    print \"Finished iteration:\", i\n",
    "print \"The accuracy is\", sum(accuracy)/len(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Testing Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section didn't end up working that well, so you can skip over it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#categories=['Wins','PPG','PPGA','PowerConf','3PG', 'APG','TOP','Conference Champ','Tourney Conference Champ',\n",
    "#           'Seed','SOS','SRS', 'RPG', 'SPG', 'Tourney Appearances','National Championships','Location']\n",
    "#accuracy=[]\n",
    "\n",
    "#for i in range(1):\n",
    "#    X_train, X_test, Y_train, Y_test = train_test_split(xTrain, yTrain)\n",
    "#    results1 = model.fit(X_train, Y_train)\n",
    "#    preds1 = model.predict(X_test)\n",
    "#    \n",
    "#    results2 = model2.fit(X_train, Y_train)\n",
    "#    preds2 = model2.predict(X_test)\n",
    "    \n",
    "#    results3 = model3.fit(X_train, Y_train)\n",
    "#    preds3 = model3.predict(X_test)\n",
    "\n",
    "#    results4 = model4.fit(X_train, Y_train)\n",
    "#    preds4 = model4.predict(X_test)\n",
    "    \n",
    "#    results5 = model5.fit(X_train, Y_train)\n",
    "#    preds5 = model5.predict(X_test)\n",
    "    \n",
    "#    preds = (preds1 + preds2 + preds3 + preds4 + preds5)/5\n",
    "\n",
    "#    preds[preds < .5] = 0\n",
    "#    preds[preds >= .5] = 1\n",
    "#    accuracy.append(np.mean(preds == Y_test))\n",
    "    #accuracy.append(np.mean(predictions == Y_test))\n",
    "#print \"The accuracy is\", sum(accuracy)/len(accuracy)\n",
    "#showFeatureImportance(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Applying the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the model you use, you will either need to return model.predict_proba or model.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def predictGame(team_1_vector, team_2_vector, home):\n",
    "    diff = [a - b for a, b in zip(team_1_vector, team_2_vector)]\n",
    "    diff.append(home)\n",
    "    return model.predict([diff]) \n",
    "    #return model.predict_proba([diff]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output here is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability that North Carolina wins: 0.482519695753\n"
     ]
    }
   ],
   "source": [
    "# This was the national championship matchup last year\n",
    "team1_name = 'North Carolina'\n",
    "team2_name = 'Villanova'\n",
    "team1_vector = getSeasonData(teams_pd[teams_pd['Team_Name'] == team1_name].values[0][0], 2016)\n",
    "team2_vector = getSeasonData(teams_pd[teams_pd['Team_Name'] == team2_name].values[0][0], 2016)\n",
    "print 'Probability that ' + team1_name + ' wins:', predictGame(team1_vector, team2_vector, 0)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Predicting NCAA Tourney 2013 - 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "For the first stage of the Kaggle competition, our job was to submit probabilities for each of the possible scenarios in the 2013, 2014, 2015, and 2016 tournaments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013_1103_1107</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013_1103_1112</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013_1103_1125</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013_1103_1129</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013_1103_1137</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  pred\n",
       "0  2013_1103_1107   0.5\n",
       "1  2013_1103_1112   0.5\n",
       "2  2013_1103_1125   0.5\n",
       "3  2013_1103_1129   0.5\n",
       "4  2013_1103_1137   0.5"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sub_pd = pd.read_csv('Data/sample_submission.csv')\n",
    "(sample_sub_pd.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def createPrediction():\n",
    "    results = [[0 for x in range(2)] for x in range(len(sample_sub_pd.index))]\n",
    "    for index, row in sample_sub_pd.iterrows():\n",
    "        matchup_id = row['id']\n",
    "        year = matchup_id[0:4]\n",
    "        team1_id = matchup_id[5:9]\n",
    "        team2_id = matchup_id[10:14]\n",
    "        team1_vector = getSeasonData(int(team1_id), int(year))\n",
    "        team2_vector = getSeasonData(int(team2_id), int(year))\n",
    "        pred = predictGame(team1_vector, team2_vector, 0)\n",
    "        results[index][0] = matchup_id\n",
    "        results[index][1] = pred[0]\n",
    "        #results[index][1] = pred[0][1]\n",
    "    results = pd.np.array(results)\n",
    "    firstRow = [[0 for x in range(2)] for x in range(1)]\n",
    "    firstRow[0][0] = 'id'\n",
    "    firstRow[0][1] = 'pred'\n",
    "    with open(\"result.csv\", \"wb\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(firstRow)\n",
    "        writer.writerows(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "createPrediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def findBestK():\n",
    "    K = (list)(i for i in range(1,200) if i%2!=0)\n",
    "    p = []\n",
    "    for k in K:\n",
    "        kmeans = KNeighborsClassifier(n_neighbors=k)\n",
    "        kmeans.fit(X_train, Y_train)\n",
    "        results = kmeans.fit(X_train, Y_train)\n",
    "        preds = kmeans.predict(X_test)\n",
    "        p.append(np.mean(preds == Y_test))\n",
    "    plt.plot(K, p)\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Selecting k with the Elbow Method')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def neuralNetwork(loops):\n",
    "    accuracy=[]\n",
    "    dim = 17\n",
    "    for i in range(loops):\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(xTrain, yTrain)\n",
    "\n",
    "        model = Sequential()\n",
    "        #model.add(Convolution1D(28, 3, border_mode='same', init='normal', input_shape=(dim, 1))) #28 1D filters of length 3\n",
    "        model.add(Dense(128, init='normal', input_dim = dim))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(64, init='normal'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(Dense(16, init='normal'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dense(2, init='normal'))\n",
    "        model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "        #X_train = X_train.reshape((len(X_train), dim, 1))\n",
    "        #X_test = X_test.reshape((len(X_test), dim, 1))\n",
    "        Y_train_categorical = np_utils.to_categorical(Y_train)\n",
    "        # TRAINING\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        model.fit(X_train, Y_train_categorical, batch_size=64, nb_epoch=10,shuffle=True)\n",
    "        preds = model.predict(X_test)\n",
    "        results=[]\n",
    "        for i in range(preds.shape[0]):\n",
    "            if preds[i][1] < .5:\n",
    "                results.append(0)\n",
    "            else:\n",
    "                results.append(1)\n",
    "        accuracy.append(np.mean(results == Y_test))\n",
    "    #accuracy.append(np.mean(predictions == Y_test))\n",
    "    print \"The accuracy is\", sum(accuracy)/len(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def getAllTeamVectors():\n",
    "    year = 2016\n",
    "    numFeatures = len(getSeasonData(1181,2012))\n",
    "    teamvecs = np.zeros(( 251, numFeatures ))\n",
    "    teams=[]\n",
    "    counter = 0\n",
    "    for team in teamList:\n",
    "        team_id = teams_pd[teams_pd['Team_Name'] == team].values[0][0]\n",
    "        team_vector = getSeasonData(team_id, year)\n",
    "        if (team_vector[0] == 0 or team_vector[4] == 0):\n",
    "            continue\n",
    "        teamvecs[counter] = team_vector\n",
    "        teams.append(team)\n",
    "        counter += 1\n",
    "    team = pd.np.array(teams)\n",
    "    team = np.reshape(team, (team.shape[0], 1))\n",
    "    with open(\"allNames.tsv\", \"wb\") as f:\n",
    "        writer = csv.writer(f, delimiter='\\t')\n",
    "        writer.writerows(team)\n",
    "    with open(\"allVecs.tsv\", \"wb\") as f:\n",
    "        writer = csv.writer(f, delimiter='\\t')\n",
    "        writer.writerows(teamvecs)\n",
    "getAllTeamVectors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is some hyperparameter optimization code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# with SVC\n",
    "#from utils import *\n",
    "#from sklearn.svm import LinearSVC\n",
    "#import time\n",
    "# split into training and testing data\n",
    "#X_train, X_test, y_train, y_test = train_test_split(xTrain, yTrain, test_size = 0.20)\n",
    "\n",
    "# create basic classifier with hardcoded hyperparams\n",
    "#linear_svm = LinearSVC(penalty='l2', loss='squared_hinge', dual=True, tol=0.0001, C=1.0) \n",
    "\n",
    "#print \"doing hyperparameter selection for linear svm\"\n",
    "#c_vals = 10.0 ** np.arange(-3, 3)\n",
    "#best = {'train error': np.inf, 'test error': np.inf, 'c':-1}\n",
    "#for c in c_vals:\n",
    "#    clf = LinearSVC(penalty='l2', loss='squared_hinge', dual=True, tol=0.0001, C=c)\n",
    "#    print \"training with c = {}\".format(c)\n",
    "#    train_err, test_err = cross_validate(clf, X_train, y_train) # implemented in utils.py\n",
    "#    if test_err < best['test error']:\n",
    "#        print \"found classifier with {}\".format(test_err)\n",
    "#        best['train error'] = train_err\n",
    "#        best['test error'] = test_err\n",
    "#        best['c'] = c\n",
    "#print best.items()\n",
    "    \n",
    "# rbf_SVM = SVC(C=1.0, kernel='rbf', gamma='auto')\n",
    "# print \"testing rbf fit\"\n",
    "# rbf_SVM.fit(X_train, y_train)\n",
    "# print \"rbf fit finished\"\n",
    "# linear_kernel_svm = SVC(C=1.0, kernel='linear')\n",
    "# # train all 3 and use k-fold CV to get error on X_train and X_test\n",
    "# classifiers = {'linear svm': linear_svm, 'rbf SVM': rbf_SVM}\n",
    "# err_dict = {}\n",
    "# for name, classifier in classifiers.items():\n",
    "#     print \"Doing k-fold CV with {}\".format(name)\n",
    "#     mean_train_err, mean_test_err = cross_validate(classifier, X_train, y_train) #implementation in utils.py\n",
    "#     print \"{} training error: {}, testing error: {}\".format(name, mean_train_err, mean_test_err)\n",
    "#     err_dict[name] = (mean_train_err, mean_test_err)\n",
    "# print err_dict\n",
    "\n",
    "# # grid search for hyperparameter selection\n",
    "# C_range = 10.0 ** np.arange(-3, 3)\n",
    "# g_range = 10.0 ** np.arange(-3, 3)\n",
    "\n",
    "# print \"doing hyperparameter selection for linear_kernel_svm\"\n",
    "# # hyperparameter selection for linear_kernel\n",
    "# best_so_far_linear = {'training error': np.inf, 'testing error': np.inf, 'c': -1}\n",
    "# for c in c_range:\n",
    "#     clf = SVC(C=c, kernel='linear')\n",
    "#     print \"training with c = {}\".format(c)\n",
    "#     train_err, test_err = cross_validate(clf, X_train, y_train)\n",
    "#     if test_err <= best_so_far_linear['testing error']:\n",
    "#         print \"best testing error: {}\".format(test_err)\n",
    "#         best_so_far_linear['training error'] = train_err\n",
    "#         best_so_far_linear['testing error'] = test_err\n",
    "#         best_so_far_linear['c'] = c\n",
    "        \n",
    "# print best_so_far_linear.items()\n",
    "\n",
    "# print \"doing hyperparameter selection for rbf SVM\"\n",
    "# best_rbf = {'training error': np.inf, 'testing error': np.inf, 'c': -1, 'g': -1}\n",
    "# for c in c_range:\n",
    "#     for g in g_range:\n",
    "#         clf = SVC(C=c, kernel='rbf', gamma=g)\n",
    "#         print \"training rbf svm with c = {}, g = {}\".format(c, g)\n",
    "#         train_err, test_err = cross_validate(clf, X_train, y_train)\n",
    "#         if test_err <= best_rbf['testing error']:\n",
    "#             print \"best testing error: {}\".format(test_err)\n",
    "#             best_rbf['training error'] = train_err\n",
    "#             best_rbf['testing error'] = test_err\n",
    "#             best_rbf['c'] = c\n",
    "#             best_rbf['g'] = g\n",
    "# print best_rbf.items()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
